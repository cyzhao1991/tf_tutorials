{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from actor import ActorNetwork\n",
    "from rbfActor import RbfActorNetwork\n",
    "from actorls import ActorLSNetwork\n",
    "from critic import CriticNetwork\n",
    "from replay_buffer import ReplayBuffer\n",
    "from ounoise import OUNoise\n",
    "import gym, time\n",
    "from Envs.reaching import ReachingEnv\n",
    "from Envs.throwing import ThrowingEnv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensor_toolbox_yyang as ttool\n",
    "\n",
    "MAX_EPISODE = 500\n",
    "MAX_TIME = 200\n",
    "\n",
    "ACTOR_LEARNING_RATE = 0.0001\n",
    "CRITIC_LEARNING_RATE = 0.001\n",
    "L2_DECAY = 0.01\n",
    "GAMMA = 0.99\n",
    "TAU = 0.001\n",
    "\n",
    "BUFFER_SIZE = 1000000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "OU_MU = 0.0\n",
    "OU_THETA = 0.15  \n",
    "OU_SIGMA = 0.20\n",
    "\n",
    "RANDOM_SEED = 1926\n",
    "\n",
    "goal_pos = np.load('./Envs/reaching_goal_pos.npy')\n",
    "source_paras = np.load('./Data/reaching_ddpg_rbf.npz')\n",
    "\n",
    "GAMMA = .99\n",
    "# env = gym.make('Pendulum-v0')\n",
    "env = ReachingEnv(include_t = True)\n",
    "# env = ThrowingEnv(include_t = True)\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_bound = env.action_space.high\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "all_weights = np.array([v[0] for v in source_paras['arr_0'][10:]])\n",
    "rank = [10,50,2]\n",
    "U, S = ttool.tucker_dcmp(all_weights, eps_or_k = rank)\n",
    "temp = np.tensordot(S, U[1], axes = (1,-1))\n",
    "L = np.tensordot(temp,U[2], axes = (1,-1))\n",
    "S = U[0][0]\n",
    "S = np.expand_dims(S, axis = -1)\n",
    "S = np.expand_dims(S, axis = -1)\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 501) (501, 2)\n",
      "(?, 501) (501, 2)\n"
     ]
    }
   ],
   "source": [
    "# actor = ActorNetwork(sess, state_dim, action_dim, action_bound, hidden_layer_dim = [40,30], \\\n",
    "#                      seed = RANDOM_SEED, tau = TAU, learning_rate = ACTOR_LEARNING_RATE)\n",
    "actor = ActorLSNetwork(sess, state_dim, action_dim, action_bound, L_init = L, S_init = S, \\\n",
    "                     seed = RANDOM_SEED, tau = TAU, learning_rate = ACTOR_LEARNING_RATE)\n",
    "\n",
    "critic = CriticNetwork(sess, state_dim, action_dim, hidden_layer_dim = [30],\\\n",
    "                       l2_alpha = L2_DECAY, seed = RANDOM_SEED, tau =TAU, learning_rate = CRITIC_LEARNING_RATE)\n",
    "replay_buffer = ReplayBuffer(BUFFER_SIZE, RANDOM_SEED)\n",
    "noise = OUNoise(action_dim, mu = OU_MU, theta = OU_THETA, sigma = OU_SIGMA, seed = RANDOM_SEED)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "summary_sum_reward_list = np.zeros([50,MAX_EPISODE])\n",
    "summary_avg_reward_list = np.zeros([50,MAX_EPISODE])\n",
    "all_recorded_actor_paras = []\n",
    "all_recorded_critic_paras = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task : 0 \t Episode: 0 \t Time_step: 199 \t Avg_reward: -47.898822022 \t Cur_reward: -47.898822022\n",
      "Task : 0 \t Episode: 1 \t Time_step: 199 \t Avg_reward: -99.9380593145 \t Cur_reward: -151.977296607\n",
      "Task : 0 \t Episode: 2 \t Time_step: 199 \t Avg_reward: -127.346324855 \t Cur_reward: -182.162855935\n",
      "Task : 0 \t Episode: 3 \t Time_step: 199 \t Avg_reward: -139.897296394 \t Cur_reward: -177.550211011\n",
      "Task : 0 \t Episode: 4 \t Time_step: 199 \t Avg_reward: -141.318897059 \t Cur_reward: -147.005299722\n",
      "Task : 0 \t Episode: 5 \t Time_step: 199 \t Avg_reward: -145.018644271 \t Cur_reward: -163.517380332\n",
      "Task : 0 \t Episode: 6 \t Time_step: 199 \t Avg_reward: -148.840958601 \t Cur_reward: -171.774844575\n",
      "Task : 0 \t Episode: 7 \t Time_step: 199 \t Avg_reward: -151.798422046 \t Cur_reward: -172.500666162\n",
      "Task : 0 \t Episode: 8 \t Time_step: 199 \t Avg_reward: -153.619663636 \t Cur_reward: -168.189596361\n",
      "Task : 0 \t Episode: 9 \t Time_step: 199 \t Avg_reward: -154.935419516 \t Cur_reward: -166.777222433\n",
      "Task : 0 \t Episode: 10 \t Time_step: 199 \t Avg_reward: -157.382647496 \t Cur_reward: -181.854927301\n",
      "Task : 0 \t Episode: 11 \t Time_step: 199 \t Avg_reward: -159.780302658 \t Cur_reward: -186.154509438\n",
      "Task : 0 \t Episode: 12 \t Time_step: 199 \t Avg_reward: -161.796244169 \t Cur_reward: -185.9875423\n",
      "Task : 0 \t Episode: 13 \t Time_step: 199 \t Avg_reward: -163.513012362 \t Cur_reward: -185.830998872\n",
      "Task : 0 \t Episode: 14 \t Time_step: 199 \t Avg_reward: -164.955009414 \t Cur_reward: -185.14296814\n",
      "Task : 0 \t Episode: 15 \t Time_step: 199 \t Avg_reward: -166.2425353 \t Cur_reward: -185.555423595\n",
      "Task : 0 \t Episode: 16 \t Time_step: 199 \t Avg_reward: -167.33861823 \t Cur_reward: -184.875945104\n",
      "Task : 0 \t Episode: 17 \t Time_step: 199 \t Avg_reward: -168.245376098 \t Cur_reward: -183.660259861\n",
      "Task : 0 \t Episode: 18 \t Time_step: 199 \t Avg_reward: -169.001453636 \t Cur_reward: -182.610849321\n",
      "Task : 0 \t Episode: 19 \t Time_step: 199 \t Avg_reward: -169.656882949 \t Cur_reward: -182.11003989\n",
      "Task : 0 \t Episode: 20 \t Time_step: 199 \t Avg_reward: -170.227339403 \t Cur_reward: -181.636468484\n",
      "Task : 0 \t Episode: 21 \t Time_step: 199 \t Avg_reward: -170.792864678 \t Cur_reward: -182.66889545\n",
      "Task : 0 \t Episode: 22 \t Time_step: 199 \t Avg_reward: -170.171236115 \t Cur_reward: -156.495407727\n",
      "Task : 0 \t Episode: 23 \t Time_step: 199 \t Avg_reward: -169.788896411 \t Cur_reward: -160.995083221\n",
      "Task : 0 \t Episode: 24 \t Time_step: 199 \t Avg_reward: -169.312120233 \t Cur_reward: -157.869491965\n",
      "Task : 0 \t Episode: 25 \t Time_step: 199 \t Avg_reward: -169.226786619 \t Cur_reward: -167.09344627\n",
      "Task : 0 \t Episode: 26 \t Time_step: 199 \t Avg_reward: -169.437477718 \t Cur_reward: -174.9154463\n",
      "Task : 0 \t Episode: 27 \t Time_step: 199 \t Avg_reward: -169.21294759 \t Cur_reward: -163.150634112\n",
      "Task : 0 \t Episode: 28 \t Time_step: 199 \t Avg_reward: -168.657436116 \t Cur_reward: -153.103114841\n",
      "Task : 0 \t Episode: 29 \t Time_step: 199 \t Avg_reward: -167.787926459 \t Cur_reward: -142.572146415\n",
      "Task : 0 \t Episode: 30 \t Time_step: 199 \t Avg_reward: -166.509649946 \t Cur_reward: -128.161354561\n",
      "Task : 0 \t Episode: 31 \t Time_step: 199 \t Avg_reward: -164.898032013 \t Cur_reward: -114.937876071\n",
      "Task : 0 \t Episode: 32 \t Time_step: 199 \t Avg_reward: -163.33429979 \t Cur_reward: -113.29486866\n",
      "Task : 0 \t Episode: 33 \t Time_step: 199 \t Avg_reward: -162.040898164 \t Cur_reward: -119.358644531\n",
      "Task : 0 \t Episode: 34 \t Time_step: 199 \t Avg_reward: -160.619365626 \t Cur_reward: -112.287259307\n",
      "Task : 0 \t Episode: 35 \t Time_step: 199 \t Avg_reward: -159.143421499 \t Cur_reward: -107.48537706\n",
      "Task : 0 \t Episode: 36 \t Time_step: 199 \t Avg_reward: -157.824823399 \t Cur_reward: -110.355291808\n",
      "Task : 0 \t Episode: 37 \t Time_step: 199 \t Avg_reward: -156.448849666 \t Cur_reward: -105.537821553\n",
      "Task : 0 \t Episode: 38 \t Time_step: 199 \t Avg_reward: -155.17680345 \t Cur_reward: -106.839047217\n",
      "Task : 0 \t Episode: 39 \t Time_step: 199 \t Avg_reward: -153.95723635 \t Cur_reward: -106.394119483\n",
      "Task : 0 \t Episode: 40 \t Time_step: 199 \t Avg_reward: -152.861990589 \t Cur_reward: -109.052160137\n",
      "Task : 0 \t Episode: 41 \t Time_step: 199 \t Avg_reward: -151.776548123 \t Cur_reward: -107.273406999\n",
      "Task : 0 \t Episode: 42 \t Time_step: 199 \t Avg_reward: -150.797544979 \t Cur_reward: -109.679412925\n",
      "Task : 0 \t Episode: 43 \t Time_step: 199 \t Avg_reward: -149.967650809 \t Cur_reward: -114.282201496\n",
      "Task : 0 \t Episode: 44 \t Time_step: 199 \t Avg_reward: -149.067906367 \t Cur_reward: -109.479150944\n",
      "Task : 0 \t Episode: 45 \t Time_step: 199 \t Avg_reward: -148.206749069 \t Cur_reward: -109.45467065\n",
      "Task : 0 \t Episode: 46 \t Time_step: 199 \t Avg_reward: -147.358670775 \t Cur_reward: -108.347069257\n",
      "Task : 0 \t Episode: 47 \t Time_step: 199 \t Avg_reward: -146.508413292 \t Cur_reward: -106.54631159\n",
      "Task : 0 \t Episode: 48 \t Time_step: 199 \t Avg_reward: -145.622600064 \t Cur_reward: -103.103565124\n",
      "Task : 0 \t Episode: 49 \t Time_step: 199 \t Avg_reward: -144.826433698 \t Cur_reward: -105.814281771\n",
      "Task : 0 \t Episode: 50 \t Time_step: 199 \t Avg_reward: -144.073229609 \t Cur_reward: -106.413025151\n",
      "Task : 0 \t Episode: 51 \t Time_step: 199 \t Avg_reward: -143.298571139 \t Cur_reward: -103.790989184\n",
      "Task : 0 \t Episode: 52 \t Time_step: 199 \t Avg_reward: -142.643579182 \t Cur_reward: -108.583997388\n",
      "Task : 0 \t Episode: 53 \t Time_step: 199 \t Avg_reward: -141.93100885 \t Cur_reward: -104.164781282\n",
      "Task : 0 \t Episode: 54 \t Time_step: 199 \t Avg_reward: -141.23521984 \t Cur_reward: -103.662613259\n",
      "Task : 0 \t Episode: 55 \t Time_step: 199 \t Avg_reward: -140.571614345 \t Cur_reward: -104.073312156\n",
      "Task : 0 \t Episode: 56 \t Time_step: 199 \t Avg_reward: -139.844049305 \t Cur_reward: -99.1004070637\n",
      "Task : 0 \t Episode: 57 \t Time_step: 199 \t Avg_reward: -139.184470714 \t Cur_reward: -101.588490987\n",
      "Task : 0 \t Episode: 58 \t Time_step: 199 \t Avg_reward: -138.568212317 \t Cur_reward: -102.825225346\n",
      "Task : 0 \t Episode: 59 \t Time_step: 199 \t Avg_reward: -137.977103999 \t Cur_reward: -103.101713197\n",
      "Task : 0 \t Episode: 60 \t Time_step: 199 \t Avg_reward: -137.369680271 \t Cur_reward: -100.924256616\n",
      "Task : 0 \t Episode: 61 \t Time_step: 199 \t Avg_reward: -136.771108317 \t Cur_reward: -100.258219094\n",
      "Task : 0 \t Episode: 62 \t Time_step: 199 \t Avg_reward: -136.236953417 \t Cur_reward: -103.119349665\n",
      "Task : 0 \t Episode: 63 \t Time_step: 199 \t Avg_reward: -135.68815325 \t Cur_reward: -101.113742717\n",
      "Task : 0 \t Episode: 64 \t Time_step: 199 \t Avg_reward: -135.141969438 \t Cur_reward: -100.186205441\n",
      "Task : 0 \t Episode: 65 \t Time_step: 199 \t Avg_reward: -134.554719063 \t Cur_reward: -96.3834446718\n",
      "Task : 0 \t Episode: 66 \t Time_step: 199 \t Avg_reward: -133.944394171 \t Cur_reward: -93.6629512965\n",
      "Task : 0 \t Episode: 67 \t Time_step: 199 \t Avg_reward: -133.280795306 \t Cur_reward: -88.8196713816\n",
      "Task : 0 \t Episode: 68 \t Time_step: 199 \t Avg_reward: -132.659145452 \t Cur_reward: -90.3869553795\n",
      "Task : 0 \t Episode: 69 \t Time_step: 199 \t Avg_reward: -132.00420234 \t Cur_reward: -86.8131276253\n",
      "Task : 0 \t Episode: 70 \t Time_step: 199 \t Avg_reward: -131.348780926 \t Cur_reward: -85.4692819612\n",
      "Task : 0 \t Episode: 71 \t Time_step: 199 \t Avg_reward: -130.675598222 \t Cur_reward: -82.8796261865\n",
      "Task : 0 \t Episode: 72 \t Time_step: 199 \t Avg_reward: -130.011220993 \t Cur_reward: -82.1760605264\n",
      "Task : 0 \t Episode: 73 \t Time_step: 199 \t Avg_reward: -129.309502565 \t Cur_reward: -78.0840573345\n",
      "Task : 0 \t Episode: 74 \t Time_step: 199 \t Avg_reward: -128.677382941 \t Cur_reward: -81.900530728\n",
      "Task : 0 \t Episode: 75 \t Time_step: 199 \t Avg_reward: -127.983546298 \t Cur_reward: -75.9457981304\n",
      "Task : 0 \t Episode: 76 \t Time_step: 199 \t Avg_reward: -127.310812262 \t Cur_reward: -76.1830255079\n",
      "Task : 0 \t Episode: 77 \t Time_step: 199 \t Avg_reward: -126.585855069 \t Cur_reward: -70.7641511902\n",
      "Task : 0 \t Episode: 78 \t Time_step: 199 \t Avg_reward: -125.836238675 \t Cur_reward: -67.3661599087\n",
      "Task : 0 \t Episode: 79 \t Time_step: 199 \t Avg_reward: -125.137125363 \t Cur_reward: -69.9071737359\n",
      "Task : 0 \t Episode: 80 \t Time_step: 199 \t Avg_reward: -124.548584896 \t Cur_reward: -77.4653475229\n",
      "Task : 0 \t Episode: 81 \t Time_step: 199 \t Avg_reward: -124.130097885 \t Cur_reward: -90.2326499933\n",
      "Task : 0 \t Episode: 82 \t Time_step: 199 \t Avg_reward: -123.77379827 \t Cur_reward: -94.5572298328\n",
      "Task : 0 \t Episode: 83 \t Time_step: 199 \t Avg_reward: -123.34991184 \t Cur_reward: -88.1673381687\n",
      "Task : 0 \t Episode: 84 \t Time_step: 199 \t Avg_reward: -122.929889677 \t Cur_reward: -87.6480279852\n",
      "Task : 0 \t Episode: 85 \t Time_step: 199 \t Avg_reward: -122.48754237 \t Cur_reward: -84.8880213145\n",
      "Task : 0 \t Episode: 86 \t Time_step: 199 \t Avg_reward: -122.014755448 \t Cur_reward: -81.3550801227\n",
      "Task : 0 \t Episode: 87 \t Time_step: 199 \t Avg_reward: -121.306762825 \t Cur_reward: -59.7114046357\n",
      "Task : 0 \t Episode: 88 \t Time_step: 199 \t Avg_reward: -120.491822436 \t Cur_reward: -48.7770682321\n",
      "Task : 0 \t Episode: 89 \t Time_step: 199 \t Avg_reward: -119.578760676 \t Cur_reward: -38.3162640189\n",
      "Task : 0 \t Episode: 90 \t Time_step: 199 \t Avg_reward: -118.679446662 \t Cur_reward: -37.7411854213\n",
      "done\n",
      "Task : 0 \t Episode: 91 \t Time_step: 151 \t Avg_reward: -117.451386518 \t Cur_reward: -5.69791342598\n",
      "Task : 0 \t Episode: 92 \t Time_step: 199 \t Avg_reward: -116.712557635 \t Cur_reward: -48.740300374\n",
      "Task : 0 \t Episode: 93 \t Time_step: 199 \t Avg_reward: -115.972144533 \t Cur_reward: -47.1137260546\n",
      "Task : 0 \t Episode: 94 \t Time_step: 199 \t Avg_reward: -115.27821987 \t Cur_reward: -50.0493015052\n",
      "Task : 0 \t Episode: 95 \t Time_step: 199 \t Avg_reward: -114.625339326 \t Cur_reward: -52.6016876783\n",
      "Task : 0 \t Episode: 96 \t Time_step: 199 \t Avg_reward: -113.97511587 \t Cur_reward: -51.5536640794\n",
      "Task : 0 \t Episode: 97 \t Time_step: 199 \t Avg_reward: -113.364736329 \t Cur_reward: -54.1579208231\n",
      "Task : 0 \t Episode: 98 \t Time_step: 199 \t Avg_reward: -112.762070914 \t Cur_reward: -53.7008603023\n",
      "Task : 0 \t Episode: 99 \t Time_step: 199 \t Avg_reward: -112.195841757 \t Cur_reward: -56.1391551828\n",
      "Task : 0 \t Episode: 100 \t Time_step: 199 \t Avg_reward: -112.243212458 \t Cur_reward: -52.6358921715\n",
      "done\n",
      "Task : 0 \t Episode: 101 \t Time_step: 45 \t Avg_reward: -110.747415934 \t Cur_reward: -2.39764412241\n",
      "done\n",
      "Task : 0 \t Episode: 102 \t Time_step: 48 \t Avg_reward: -108.953069496 \t Cur_reward: -2.72821220809\n",
      "Task : 0 \t Episode: 103 \t Time_step: 199 \t Avg_reward: -107.764212329 \t Cur_reward: -58.6644943236\n",
      "Task : 0 \t Episode: 104 \t Time_step: 199 \t Avg_reward: -106.831747842 \t Cur_reward: -53.7588510049\n",
      "Task : 0 \t Episode: 105 \t Time_step: 199 \t Avg_reward: -105.791997757 \t Cur_reward: -59.5423718156\n",
      "Task : 0 \t Episode: 106 \t Time_step: 199 \t Avg_reward: -104.656811667 \t Cur_reward: -58.2562355431\n",
      "done\n",
      "Task : 0 \t Episode: 107 \t Time_step: 47 \t Avg_reward: -102.955416532 \t Cur_reward: -2.361152682\n",
      "Task : 0 \t Episode: 108 \t Time_step: 199 \t Avg_reward: -101.849090368 \t Cur_reward: -57.5569799565\n",
      "done\n",
      "Task : 0 \t Episode: 109 \t Time_step: 48 \t Avg_reward: -100.201747145 \t Cur_reward: -2.04290009036\n",
      "Task : 0 \t Episode: 110 \t Time_step: 199 \t Avg_reward: -98.975265992 \t Cur_reward: -59.206812049\n",
      "Task : 0 \t Episode: 111 \t Time_step: 199 \t Avg_reward: -97.7113883983 \t Cur_reward: -59.7667500628\n",
      "Task : 0 \t Episode: 112 \t Time_step: 199 \t Avg_reward: -96.448002754 \t Cur_reward: -59.6489778715\n",
      "Task : 0 \t Episode: 113 \t Time_step: 199 \t Avg_reward: -95.175229507 \t Cur_reward: -58.5536741745\n",
      "Task : 0 \t Episode: 114 \t Time_step: 199 \t Avg_reward: -93.8830739927 \t Cur_reward: -55.9274167092\n",
      "Task : 0 \t Episode: 115 \t Time_step: 199 \t Avg_reward: -92.56731826 \t Cur_reward: -53.9798503284\n",
      "done\n",
      "Task : 0 \t Episode: 116 \t Time_step: 62 \t Avg_reward: -90.7448002321 \t Cur_reward: -2.62414231168\n",
      "Task : 0 \t Episode: 117 \t Time_step: 199 \t Avg_reward: -89.4496992137 \t Cur_reward: -54.150158019\n",
      "Task : 0 \t Episode: 118 \t Time_step: 199 \t Avg_reward: -88.1381716732 \t Cur_reward: -51.4580952728\n",
      "Task : 0 \t Episode: 119 \t Time_step: 199 \t Avg_reward: -86.8843012534 \t Cur_reward: -56.7229979069\n",
      "done\n",
      "Task : 0 \t Episode: 120 \t Time_step: 67 \t Avg_reward: -85.0962340561 \t Cur_reward: -2.82974875913\n",
      "Task : 0 \t Episode: 121 \t Time_step: 199 \t Avg_reward: -83.8220479386 \t Cur_reward: -55.2502836943\n",
      "Task : 0 \t Episode: 122 \t Time_step: 199 \t Avg_reward: -82.7382634465 \t Cur_reward: -48.1169585246\n",
      "Task : 0 \t Episode: 123 \t Time_step: 199 \t Avg_reward: -81.6418856009 \t Cur_reward: -51.3572986522\n",
      "Task : 0 \t Episode: 124 \t Time_step: 199 \t Avg_reward: -80.5650073175 \t Cur_reward: -50.1816636283\n",
      "Task : 0 \t Episode: 125 \t Time_step: 199 \t Avg_reward: -79.4034855582 \t Cur_reward: -50.9412703435\n",
      "Task : 0 \t Episode: 126 \t Time_step: 199 \t Avg_reward: -78.1559821454 \t Cur_reward: -50.1651050179\n",
      "done\n",
      "Task : 0 \t Episode: 127 \t Time_step: 77 \t Avg_reward: -76.5482057921 \t Cur_reward: -2.37299878486\n",
      "Task : 0 \t Episode: 128 \t Time_step: 199 \t Avg_reward: -75.3020885864 \t Cur_reward: -28.4913942674\n",
      "Task : 0 \t Episode: 129 \t Time_step: 199 \t Avg_reward: -74.1467778187 \t Cur_reward: -27.0410696506\n",
      "Task : 0 \t Episode: 130 \t Time_step: 199 \t Avg_reward: -73.1772157991 \t Cur_reward: -31.2051525941\n",
      "Task : 0 \t Episode: 131 \t Time_step: 199 \t Avg_reward: -72.3258018031 \t Cur_reward: -29.7964764763\n",
      "Task : 0 \t Episode: 132 \t Time_step: 199 \t Avg_reward: -71.4541804238 \t Cur_reward: -26.1327307262\n",
      "Task : 0 \t Episode: 133 \t Time_step: 199 \t Avg_reward: -70.4566936418 \t Cur_reward: -19.6099663326\n",
      "Task : 0 \t Episode: 134 \t Time_step: 199 \t Avg_reward: -69.5738169099 \t Cur_reward: -23.9995861158\n",
      "Task : 0 \t Episode: 135 \t Time_step: 199 \t Avg_reward: -68.7800192768 \t Cur_reward: -28.105613751\n",
      "Task : 0 \t Episode: 136 \t Time_step: 199 \t Avg_reward: -67.9139130721 \t Cur_reward: -23.7446713363\n",
      "Task : 0 \t Episode: 137 \t Time_step: 199 \t Avg_reward: -67.1377524163 \t Cur_reward: -27.9217559698\n",
      "Task : 0 \t Episode: 138 \t Time_step: 199 \t Avg_reward: -66.2794698284 \t Cur_reward: -21.0107884317\n",
      "Task : 0 \t Episode: 139 \t Time_step: 199 \t Avg_reward: -65.4883230947 \t Cur_reward: -27.2794461173\n",
      "Task : 0 \t Episode: 140 \t Time_step: 199 \t Avg_reward: -64.681559176 \t Cur_reward: -28.3757682612\n",
      "done\n",
      "Task : 0 \t Episode: 141 \t Time_step: 84 \t Avg_reward: -63.6420662825 \t Cur_reward: -3.324117651\n",
      "done\n",
      "Task : 0 \t Episode: 142 \t Time_step: 90 \t Avg_reward: -62.5702233273 \t Cur_reward: -2.49511740339\n",
      "Task : 0 \t Episode: 143 \t Time_step: 199 \t Avg_reward: -61.6812492268 \t Cur_reward: -25.3847914484\n",
      "Task : 0 \t Episode: 144 \t Time_step: 199 \t Avg_reward: -60.8536712181 \t Cur_reward: -26.7213500707\n",
      "done\n",
      "Task : 0 \t Episode: 145 \t Time_step: 85 \t Avg_reward: -59.7873685924 \t Cur_reward: -2.82440808167\n",
      "Task : 0 \t Episode: 146 \t Time_step: 199 \t Avg_reward: -58.9750702331 \t Cur_reward: -27.1172333303\n",
      "done\n",
      "Task : 0 \t Episode: 147 \t Time_step: 90 \t Avg_reward: -57.937518584 \t Cur_reward: -2.79114667496\n",
      "Task : 0 \t Episode: 148 \t Time_step: 199 \t Avg_reward: -57.093664414 \t Cur_reward: -18.7181481308\n",
      "done\n",
      "Task : 0 \t Episode: 149 \t Time_step: 89 \t Avg_reward: -56.0609326488 \t Cur_reward: -2.54110524279\n",
      "Task : 0 \t Episode: 150 \t Time_step: 199 \t Avg_reward: -55.2372985938 \t Cur_reward: -24.049619654\n",
      "done\n",
      "Task : 0 \t Episode: 151 \t Time_step: 90 \t Avg_reward: -54.2269894006 \t Cur_reward: -2.76006986098\n",
      "Task : 0 \t Episode: 152 \t Time_step: 199 \t Avg_reward: -53.3474961969 \t Cur_reward: -20.6346770229\n",
      "Task : 0 \t Episode: 153 \t Time_step: 199 \t Avg_reward: -52.5648033753 \t Cur_reward: -25.8954991193\n",
      "Task : 0 \t Episode: 154 \t Time_step: 199 \t Avg_reward: -51.7107992758 \t Cur_reward: -18.2622033094\n",
      "Task : 0 \t Episode: 155 \t Time_step: 199 \t Avg_reward: -50.8672873592 \t Cur_reward: -19.7221204979\n",
      "Task : 0 \t Episode: 156 \t Time_step: 199 \t Avg_reward: -50.0305942069 \t Cur_reward: -15.4310918372\n",
      "Task : 0 \t Episode: 157 \t Time_step: 199 \t Avg_reward: -49.2089644772 \t Cur_reward: -19.4255180119\n",
      "Task : 0 \t Episode: 158 \t Time_step: 199 \t Avg_reward: -48.3180160182 \t Cur_reward: -13.7303794431\n",
      "Task : 0 \t Episode: 159 \t Time_step: 199 \t Avg_reward: -47.4525050607 \t Cur_reward: -16.5506174507\n",
      "done\n",
      "Task : 0 \t Episode: 160 \t Time_step: 85 \t Avg_reward: -46.4732412433 \t Cur_reward: -2.99787487943\n",
      "Task : 0 \t Episode: 161 \t Time_step: 199 \t Avg_reward: -45.6637375202 \t Cur_reward: -19.3078467764\n",
      "done\n",
      "Task : 0 \t Episode: 162 \t Time_step: 91 \t Avg_reward: -44.670352444 \t Cur_reward: -3.78084204538\n",
      "done\n",
      "Task : 0 \t Episode: 163 \t Time_step: 88 \t Avg_reward: -43.68230266 \t Cur_reward: -2.30876431798\n",
      "done\n",
      "Task : 0 \t Episode: 164 \t Time_step: 94 \t Avg_reward: -42.7168047934 \t Cur_reward: -3.63641878654\n",
      "done\n",
      "Task : 0 \t Episode: 165 \t Time_step: 86 \t Avg_reward: -41.7875414114 \t Cur_reward: -3.45710647099\n",
      "Task : 0 \t Episode: 166 \t Time_step: 199 \t Avg_reward: -41.0401955665 \t Cur_reward: -18.9283668033\n",
      "done\n",
      "Task : 0 \t Episode: 167 \t Time_step: 92 \t Avg_reward: -40.2149005672 \t Cur_reward: -6.29017145301\n",
      "done\n",
      "Task : 0 \t Episode: 168 \t Time_step: 91 \t Avg_reward: -39.3749085351 \t Cur_reward: -6.38775216569\n",
      "done\n",
      "Task : 0 \t Episode: 169 \t Time_step: 94 \t Avg_reward: -38.5570254329 \t Cur_reward: -5.02481740425\n",
      "Task : 0 \t Episode: 170 \t Time_step: 199 \t Avg_reward: -37.8844634053 \t Cur_reward: -18.2130792061\n",
      "done\n",
      "Task : 0 \t Episode: 171 \t Time_step: 91 \t Avg_reward: -37.1232474948 \t Cur_reward: -6.7580351391\n",
      "done\n",
      "Task : 0 \t Episode: 172 \t Time_step: 92 \t Avg_reward: -36.3672136516 \t Cur_reward: -6.5726762043\n",
      "done\n",
      "Task : 0 \t Episode: 173 \t Time_step: 89 \t Avg_reward: -35.6206443117 \t Cur_reward: -3.42712334168\n",
      "Task : 0 \t Episode: 174 \t Time_step: 199 \t Avg_reward: -34.9530500136 \t Cur_reward: -15.1411009147\n",
      "done\n",
      "Task : 0 \t Episode: 175 \t Time_step: 95 \t Avg_reward: -34.2633911026 \t Cur_reward: -6.97990703613\n",
      "Task : 0 \t Episode: 176 \t Time_step: 199 \t Avg_reward: -33.6241612315 \t Cur_reward: -12.2600383918\n",
      "done\n",
      "Task : 0 \t Episode: 177 \t Time_step: 90 \t Avg_reward: -32.9534008348 \t Cur_reward: -3.68811152127\n",
      "done\n",
      "Task : 0 \t Episode: 178 \t Time_step: 102 \t Avg_reward: -32.3318210287 \t Cur_reward: -5.20817930007\n",
      "done\n",
      "Task : 0 \t Episode: 179 \t Time_step: 101 \t Avg_reward: -31.6631411761 \t Cur_reward: -3.03918848002\n",
      "done\n",
      "Task : 0 \t Episode: 180 \t Time_step: 117 \t Avg_reward: -30.9163500907 \t Cur_reward: -2.7862389847\n",
      "done\n",
      "Task : 0 \t Episode: 181 \t Time_step: 90 \t Avg_reward: -30.060464416 \t Cur_reward: -4.64408252333\n",
      "done\n",
      "Task : 0 \t Episode: 182 \t Time_step: 75 \t Avg_reward: -29.1408778729 \t Cur_reward: -2.59857551691\n",
      "done\n",
      "Task : 0 \t Episode: 183 \t Time_step: 101 \t Avg_reward: -28.3212945271 \t Cur_reward: -6.20900358951\n",
      "done\n",
      "Task : 0 \t Episode: 184 \t Time_step: 77 \t Avg_reward: -27.4855078756 \t Cur_reward: -4.06936283819\n",
      "done\n",
      "Task : 0 \t Episode: 185 \t Time_step: 97 \t Avg_reward: -26.6787395154 \t Cur_reward: -4.21118529278\n",
      "done\n",
      "Task : 0 \t Episode: 186 \t Time_step: 106 \t Avg_reward: -25.8954419534 \t Cur_reward: -3.02532392272\n",
      "done\n",
      "Task : 0 \t Episode: 187 \t Time_step: 119 \t Avg_reward: -25.3310263461 \t Cur_reward: -3.26984391\n",
      "done\n",
      "Task : 0 \t Episode: 188 \t Time_step: 69 \t Avg_reward: -24.8617325179 \t Cur_reward: -1.84768540327\n",
      "done\n",
      "Task : 0 \t Episode: 189 \t Time_step: 130 \t Avg_reward: -24.5112626098 \t Cur_reward: -3.2692732137\n",
      "done\n",
      "Task : 0 \t Episode: 190 \t Time_step: 94 \t Avg_reward: -24.174874766 \t Cur_reward: -4.10240103823\n",
      "done\n",
      "Task : 0 \t Episode: 191 \t Time_step: 105 \t Avg_reward: -24.1551630825 \t Cur_reward: -3.72674507536\n",
      "done\n",
      "Task : 0 \t Episode: 192 \t Time_step: 124 \t Avg_reward: -23.6950352543 \t Cur_reward: -2.72751755242\n",
      "done\n",
      "Task : 0 \t Episode: 193 \t Time_step: 66 \t Avg_reward: -23.2521356169 \t Cur_reward: -2.82376231717\n",
      "done\n",
      "Task : 0 \t Episode: 194 \t Time_step: 108 \t Avg_reward: -22.7910546101 \t Cur_reward: -3.94120082643\n",
      "done\n",
      "Task : 0 \t Episode: 195 \t Time_step: 98 \t Avg_reward: -22.2989750456 \t Cur_reward: -3.39373122624\n",
      "done\n",
      "Task : 0 \t Episode: 196 \t Time_step: 112 \t Avg_reward: -21.8165556702 \t Cur_reward: -3.31172654133\n",
      "done\n",
      "Task : 0 \t Episode: 197 \t Time_step: 84 \t Avg_reward: -21.3211500561 \t Cur_reward: -4.61735941594\n",
      "done\n",
      "Task : 0 \t Episode: 198 \t Time_step: 91 \t Avg_reward: -20.8159186326 \t Cur_reward: -3.1777179474\n",
      "done\n",
      "Task : 0 \t Episode: 199 \t Time_step: 108 \t Avg_reward: -20.2861631979 \t Cur_reward: -3.16361172033\n",
      "done\n",
      "Task : 0 \t Episode: 200 \t Time_step: 63 \t Avg_reward: -19.7870565809 \t Cur_reward: -2.72523047052\n",
      "done\n",
      "Task : 0 \t Episode: 201 \t Time_step: 118 \t Avg_reward: -19.7991173235 \t Cur_reward: -3.60371838366\n",
      "done\n",
      "Task : 0 \t Episode: 202 \t Time_step: 81 \t Avg_reward: -19.801923122 \t Cur_reward: -3.00879204972\n",
      "done\n",
      "Task : 0 \t Episode: 203 \t Time_step: 74 \t Avg_reward: -19.2468869142 \t Cur_reward: -3.16087355075\n",
      "done\n",
      "Task : 0 \t Episode: 204 \t Time_step: 89 \t Avg_reward: -18.7543744486 \t Cur_reward: -4.50760444628\n",
      "done\n",
      "Task : 0 \t Episode: 205 \t Time_step: 86 \t Avg_reward: -18.19291273 \t Cur_reward: -3.396199947\n",
      "done\n",
      "Task : 0 \t Episode: 206 \t Time_step: 104 \t Avg_reward: -17.6482238719 \t Cur_reward: -3.78734973741\n",
      "Task : 0 \t Episode: 207 \t Time_step: 199 \t Avg_reward: -17.8463705794 \t Cur_reward: -22.1758234349\n",
      "Task : 0 \t Episode: 208 \t Time_step: 199 \t Avg_reward: -17.4665910477 \t Cur_reward: -19.5790267846\n",
      "done\n",
      "Task : 0 \t Episode: 209 \t Time_step: 130 \t Avg_reward: -17.5628358223 \t Cur_reward: -11.6673775514\n",
      "done\n",
      "Task : 0 \t Episode: 210 \t Time_step: 76 \t Avg_reward: -17.0188450283 \t Cur_reward: -4.80773265012\n",
      "Task : 0 \t Episode: 211 \t Time_step: 199 \t Avg_reward: -16.5683982835 \t Cur_reward: -14.7220755757\n",
      "done\n",
      "Task : 0 \t Episode: 212 \t Time_step: 96 \t Avg_reward: -16.005927471 \t Cur_reward: -3.40189662652\n",
      "done\n",
      "Task : 0 \t Episode: 213 \t Time_step: 92 \t Avg_reward: -15.4906665474 \t Cur_reward: -7.02758181593\n",
      "done\n",
      "Task : 0 \t Episode: 214 \t Time_step: 103 \t Avg_reward: -14.9833774546 \t Cur_reward: -5.19850742891\n",
      "done\n",
      "Task : 0 \t Episode: 215 \t Time_step: 97 \t Avg_reward: -14.4748557175 \t Cur_reward: -3.1276766162\n",
      "done\n",
      "Task : 0 \t Episode: 216 \t Time_step: 134 \t Avg_reward: -14.4842043205 \t Cur_reward: -3.55900260667\n",
      "done\n",
      "Task : 0 \t Episode: 217 \t Time_step: 114 \t Avg_reward: -13.9775839794 \t Cur_reward: -3.48812391573\n",
      "done\n",
      "Task : 0 \t Episode: 218 \t Time_step: 116 \t Avg_reward: -13.495609178 \t Cur_reward: -3.26061513122\n",
      "done\n",
      "Task : 0 \t Episode: 219 \t Time_step: 134 \t Avg_reward: -12.96860165 \t Cur_reward: -4.02224510432\n",
      "done\n",
      "Task : 0 \t Episode: 220 \t Time_step: 133 \t Avg_reward: -12.9847259575 \t Cur_reward: -4.44217951455\n",
      "done\n",
      "Task : 0 \t Episode: 221 \t Time_step: 134 \t Avg_reward: -12.4695648376 \t Cur_reward: -3.73417170337\n",
      "Task : 0 \t Episode: 222 \t Time_step: 199 \t Avg_reward: -12.1021936382 \t Cur_reward: -11.3798385832\n",
      "done\n",
      "Task : 0 \t Episode: 223 \t Time_step: 128 \t Avg_reward: -11.6419710272 \t Cur_reward: -5.33503755018\n",
      "Task : 0 \t Episode: 224 \t Time_step: 199 \t Avg_reward: -11.275519029 \t Cur_reward: -13.5364638061\n",
      "Task : 0 \t Episode: 225 \t Time_step: 199 \t Avg_reward: -10.8894771197 \t Cur_reward: -12.3370794124\n",
      "done\n",
      "Task : 0 \t Episode: 226 \t Time_step: 119 \t Avg_reward: -10.4386351086 \t Cur_reward: -5.0809039126\n",
      "done\n",
      "Task : 0 \t Episode: 227 \t Time_step: 127 \t Avg_reward: -10.4600601808 \t Cur_reward: -4.51550600482\n",
      "done\n",
      "Task : 0 \t Episode: 228 \t Time_step: 90 \t Avg_reward: -10.2114461414 \t Cur_reward: -3.62999033032\n",
      "done\n",
      "Task : 0 \t Episode: 229 \t Time_step: 110 \t Avg_reward: -9.99280790836 \t Cur_reward: -5.17724634335\n",
      "done\n",
      "Task : 0 \t Episode: 230 \t Time_step: 84 \t Avg_reward: -9.73045470004 \t Cur_reward: -4.96983176155\n",
      "done\n",
      "Task : 0 \t Episode: 231 \t Time_step: 81 \t Avg_reward: -9.45398054128 \t Cur_reward: -2.14906060056\n",
      "done\n",
      "Task : 0 \t Episode: 232 \t Time_step: 156 \t Avg_reward: -9.23204069851 \t Cur_reward: -3.93874644897\n",
      "done\n",
      "Task : 0 \t Episode: 233 \t Time_step: 129 \t Avg_reward: -9.08256653721 \t Cur_reward: -4.66255020329\n",
      "done\n",
      "Task : 0 \t Episode: 234 \t Time_step: 137 \t Avg_reward: -8.87414059909 \t Cur_reward: -3.15699230307\n",
      "done\n",
      "Task : 0 \t Episode: 235 \t Time_step: 111 \t Avg_reward: -8.66223587928 \t Cur_reward: -6.9151417703\n",
      "done\n",
      "Task : 0 \t Episode: 236 \t Time_step: 132 \t Avg_reward: -8.48781609977 \t Cur_reward: -6.30269338548\n",
      "done\n",
      "Task : 0 \t Episode: 237 \t Time_step: 126 \t Avg_reward: -8.25021735592 \t Cur_reward: -4.16188158515\n",
      "done\n",
      "Task : 0 \t Episode: 238 \t Time_step: 107 \t Avg_reward: -8.07686626456 \t Cur_reward: -3.67567929549\n",
      "Task : 0 \t Episode: 239 \t Time_step: 199 \t Avg_reward: -7.8985033578 \t Cur_reward: -9.44315544125\n",
      "done\n",
      "Task : 0 \t Episode: 240 \t Time_step: 78 \t Avg_reward: -7.65465806032 \t Cur_reward: -3.99123851321\n",
      "done\n",
      "Task : 0 \t Episode: 241 \t Time_step: 119 \t Avg_reward: -7.67343183242 \t Cur_reward: -5.20149486081\n",
      "done\n",
      "Task : 0 \t Episode: 242 \t Time_step: 117 \t Avg_reward: -7.67384765494 \t Cur_reward: -2.53669965562\n",
      "Task : 0 \t Episode: 243 \t Time_step: 199 \t Avg_reward: -7.49045053639 \t Cur_reward: -7.04507959278\n",
      "Task : 0 \t Episode: 244 \t Time_step: 199 \t Avg_reward: -7.32466646321 \t Cur_reward: -10.1429427531\n",
      "done\n",
      "Task : 0 \t Episode: 245 \t Time_step: 121 \t Avg_reward: -7.34599170142 \t Cur_reward: -4.95693190294\n",
      "done\n",
      "Task : 0 \t Episode: 246 \t Time_step: 119 \t Avg_reward: -7.11916215279 \t Cur_reward: -4.43427846727\n",
      "Task : 0 \t Episode: 247 \t Time_step: 199 \t Avg_reward: -7.16168804159 \t Cur_reward: -7.04373555424\n",
      "Task : 0 \t Episode: 248 \t Time_step: 199 \t Avg_reward: -7.03902672174 \t Cur_reward: -6.45201614577\n",
      "done\n",
      "Task : 0 \t Episode: 249 \t Time_step: 122 \t Avg_reward: -7.09518496352 \t Cur_reward: -8.15692942066\n",
      "done\n",
      "Task : 0 \t Episode: 250 \t Time_step: 129 \t Avg_reward: -6.89263878518 \t Cur_reward: -3.79500182013\n",
      "Task : 0 \t Episode: 251 \t Time_step: 199 \t Avg_reward: -6.9432756928 \t Cur_reward: -7.82376062282\n",
      "Task : 0 \t Episode: 252 \t Time_step: 199 \t Avg_reward: -6.82453876552 \t Cur_reward: -8.76098429551\n",
      "done\n",
      "Task : 0 \t Episode: 253 \t Time_step: 114 \t Avg_reward: -6.61827382577 \t Cur_reward: -5.26900514424\n",
      "done\n",
      "Task : 0 \t Episode: 254 \t Time_step: 81 \t Avg_reward: -6.46550025151 \t Cur_reward: -2.98484588376\n",
      "done\n",
      "Task : 0 \t Episode: 255 \t Time_step: 173 \t Avg_reward: -6.31836110581 \t Cur_reward: -5.00820592764\n",
      "done\n",
      "Task : 0 \t Episode: 256 \t Time_step: 172 \t Avg_reward: -6.21056185614 \t Cur_reward: -4.65116687026\n",
      "done\n",
      "Task : 0 \t Episode: 257 \t Time_step: 117 \t Avg_reward: -6.05301273703 \t Cur_reward: -3.67060610035\n",
      "done\n",
      "Task : 0 \t Episode: 258 \t Time_step: 61 \t Avg_reward: -5.94323796726 \t Cur_reward: -2.75290246668\n",
      "done\n",
      "Task : 0 \t Episode: 259 \t Time_step: 116 \t Avg_reward: -5.81813202498 \t Cur_reward: -4.04002322213\n",
      "done\n",
      "Task : 0 \t Episode: 260 \t Time_step: 111 \t Avg_reward: -5.83858946536 \t Cur_reward: -5.0436189174\n",
      "done\n",
      "Task : 0 \t Episode: 261 \t Time_step: 135 \t Avg_reward: -5.70843320215 \t Cur_reward: -6.29222045612\n",
      "done\n",
      "Task : 0 \t Episode: 262 \t Time_step: 108 \t Avg_reward: -5.71469710005 \t Cur_reward: -4.40723183547\n",
      "done\n",
      "Task : 0 \t Episode: 263 \t Time_step: 117 \t Avg_reward: -5.73431897557 \t Cur_reward: -4.27095186966\n",
      "done\n",
      "Task : 0 \t Episode: 264 \t Time_step: 101 \t Avg_reward: -5.73584755375 \t Cur_reward: -3.78927660423\n",
      "done\n",
      "Task : 0 \t Episode: 265 \t Time_step: 153 \t Avg_reward: -5.76115602325 \t Cur_reward: -5.98795342117\n",
      "done\n",
      "Task : 0 \t Episode: 266 \t Time_step: 68 \t Avg_reward: -5.59802229623 \t Cur_reward: -2.61499410132\n",
      "done\n",
      "Task : 0 \t Episode: 267 \t Time_step: 119 \t Avg_reward: -5.56612853308 \t Cur_reward: -3.100795138\n",
      "done\n",
      "Task : 0 \t Episode: 268 \t Time_step: 94 \t Avg_reward: -5.56422732726 \t Cur_reward: -6.19763158411\n",
      "done\n",
      "Task : 0 \t Episode: 269 \t Time_step: 119 \t Avg_reward: -5.5536393246 \t Cur_reward: -3.96601713817\n",
      "done\n",
      "Task : 0 \t Episode: 270 \t Time_step: 138 \t Avg_reward: -5.42523307305 \t Cur_reward: -5.37245405103\n",
      "done\n",
      "Task : 0 \t Episode: 271 \t Time_step: 110 \t Avg_reward: -5.39181726461 \t Cur_reward: -3.41645429514\n",
      "done\n",
      "Task : 0 \t Episode: 272 \t Time_step: 123 \t Avg_reward: -5.35711679767 \t Cur_reward: -3.10262951024\n",
      "done\n",
      "Task : 0 \t Episode: 273 \t Time_step: 103 \t Avg_reward: -5.36903884921 \t Cur_reward: -4.61932849591\n",
      "done\n",
      "Task : 0 \t Episode: 274 \t Time_step: 110 \t Avg_reward: -5.26177688956 \t Cur_reward: -4.41490494921\n",
      "Task : 0 \t Episode: 275 \t Time_step: 199 \t Avg_reward: -5.26222477893 \t Cur_reward: -7.02469597337\n",
      "done\n",
      "Task : 0 \t Episode: 276 \t Time_step: 113 \t Avg_reward: -5.18198676558 \t Cur_reward: -4.23623705692\n",
      "done\n",
      "Task : 0 \t Episode: 277 \t Time_step: 100 \t Avg_reward: -5.18161231953 \t Cur_reward: -3.65066691588\n",
      "done\n",
      "Task : 0 \t Episode: 278 \t Time_step: 152 \t Avg_reward: -5.16441521911 \t Cur_reward: -3.48846925783\n",
      "done\n",
      "Task : 0 \t Episode: 279 \t Time_step: 76 \t Avg_reward: -5.16807771386 \t Cur_reward: -3.40543795499\n",
      "done\n",
      "Task : 0 \t Episode: 280 \t Time_step: 136 \t Avg_reward: -5.17676354825 \t Cur_reward: -3.65482242373\n",
      "done\n",
      "Task : 0 \t Episode: 281 \t Time_step: 113 \t Avg_reward: -5.16712188475 \t Cur_reward: -3.67991617353\n",
      "done\n",
      "Task : 0 \t Episode: 282 \t Time_step: 129 \t Avg_reward: -5.18756176192 \t Cur_reward: -4.64256323382\n",
      "done\n",
      "Task : 0 \t Episode: 283 \t Time_step: 101 \t Avg_reward: -5.16703291985 \t Cur_reward: -4.15611938257\n",
      "done\n",
      "Task : 0 \t Episode: 284 \t Time_step: 115 \t Avg_reward: -5.15511515762 \t Cur_reward: -2.87758661498\n",
      "Task : 0 \t Episode: 285 \t Time_step: 199 \t Avg_reward: -5.21050852487 \t Cur_reward: -9.75052201861\n",
      "done\n",
      "Task : 0 \t Episode: 286 \t Time_step: 105 \t Avg_reward: -5.22211274381 \t Cur_reward: -4.18574581673\n",
      "done\n",
      "Task : 0 \t Episode: 287 \t Time_step: 116 \t Avg_reward: -5.22741736713 \t Cur_reward: -3.8003062415\n",
      "done\n",
      "Task : 0 \t Episode: 288 \t Time_step: 150 \t Avg_reward: -5.25288462653 \t Cur_reward: -4.39441134336\n",
      "done\n",
      "Task : 0 \t Episode: 289 \t Time_step: 106 \t Avg_reward: -5.25632199204 \t Cur_reward: -3.61300976475\n",
      "done\n",
      "Task : 0 \t Episode: 290 \t Time_step: 120 \t Avg_reward: -5.25549616876 \t Cur_reward: -4.0198187105\n",
      "done\n",
      "Task : 0 \t Episode: 291 \t Time_step: 116 \t Avg_reward: -5.26900928317 \t Cur_reward: -5.07805651558\n",
      "done\n",
      "Task : 0 \t Episode: 292 \t Time_step: 109 \t Avg_reward: -5.29425215127 \t Cur_reward: -5.25180436271\n",
      "done\n",
      "Task : 0 \t Episode: 293 \t Time_step: 131 \t Avg_reward: -5.30932701823 \t Cur_reward: -4.33124901315\n",
      "done\n",
      "Task : 0 \t Episode: 294 \t Time_step: 117 \t Avg_reward: -5.31268873775 \t Cur_reward: -4.2773727788\n",
      "done\n",
      "Task : 0 \t Episode: 295 \t Time_step: 104 \t Avg_reward: -5.31512415452 \t Cur_reward: -3.6372729034\n",
      "done\n",
      "Task : 0 \t Episode: 296 \t Time_step: 121 \t Avg_reward: -5.34324470298 \t Cur_reward: -6.12378138656\n",
      "done\n",
      "Task : 0 \t Episode: 297 \t Time_step: 150 \t Avg_reward: -5.34871130392 \t Cur_reward: -5.16401951018\n",
      "done\n",
      "Task : 0 \t Episode: 298 \t Time_step: 96 \t Avg_reward: -5.35467069432 \t Cur_reward: -3.77365698764\n",
      "done\n",
      "Task : 0 \t Episode: 299 \t Time_step: 145 \t Avg_reward: -5.36443504948 \t Cur_reward: -4.14004723617\n",
      "done\n",
      "Task : 0 \t Episode: 300 \t Time_step: 102 \t Avg_reward: -5.37729813628 \t Cur_reward: -4.01153915084\n",
      "done\n",
      "Task : 0 \t Episode: 301 \t Time_step: 119 \t Avg_reward: -5.37638531439 \t Cur_reward: -3.51243619399\n",
      "done\n",
      "Task : 0 \t Episode: 302 \t Time_step: 97 \t Avg_reward: -5.38181917179 \t Cur_reward: -3.55217779016\n",
      "Task : 0 \t Episode: 303 \t Time_step: 199 \t Avg_reward: -5.42666904664 \t Cur_reward: -7.64586103594\n",
      "done\n",
      "Task : 0 \t Episode: 304 \t Time_step: 107 \t Avg_reward: -5.41652741395 \t Cur_reward: -3.49344117741\n",
      "done\n",
      "Task : 0 \t Episode: 305 \t Time_step: 90 \t Avg_reward: -5.41757084787 \t Cur_reward: -3.50054333902\n",
      "done\n",
      "Task : 0 \t Episode: 306 \t Time_step: 128 \t Avg_reward: -5.42930111561 \t Cur_reward: -4.96037651142\n",
      "done\n",
      "Task : 0 \t Episode: 307 \t Time_step: 116 \t Avg_reward: -5.25005646482 \t Cur_reward: -4.25135835561\n",
      "Task : 0 \t Episode: 308 \t Time_step: 199 \t Avg_reward: -5.11490465624 \t Cur_reward: -6.0638459264\n",
      "done\n",
      "Task : 0 \t Episode: 309 \t Time_step: 149 \t Avg_reward: -5.04508061415 \t Cur_reward: -4.68497334281\n",
      "done\n",
      "Task : 0 \t Episode: 310 \t Time_step: 149 \t Avg_reward: -5.03590538465 \t Cur_reward: -3.89020969995\n",
      "done\n",
      "Task : 0 \t Episode: 311 \t Time_step: 122 \t Avg_reward: -4.92613046371 \t Cur_reward: -3.74458348167\n",
      "done\n",
      "Task : 0 \t Episode: 312 \t Time_step: 107 \t Avg_reward: -4.92231436567 \t Cur_reward: -3.02028682216\n",
      "done\n",
      "Task : 0 \t Episode: 313 \t Time_step: 102 \t Avg_reward: -4.9050289627 \t Cur_reward: -5.29904151938\n",
      "done\n",
      "Task : 0 \t Episode: 314 \t Time_step: 111 \t Avg_reward: -4.90289042426 \t Cur_reward: -4.98465358435\n",
      "done\n",
      "Task : 0 \t Episode: 315 \t Time_step: 147 \t Avg_reward: -4.91988940837 \t Cur_reward: -4.82757502813\n",
      "done\n",
      "Task : 0 \t Episode: 316 \t Time_step: 71 \t Avg_reward: -4.91325543592 \t Cur_reward: -2.8956053614\n",
      "done\n",
      "Task : 0 \t Episode: 317 \t Time_step: 152 \t Avg_reward: -4.9249820769 \t Cur_reward: -4.66078801395\n",
      "done\n",
      "Task : 0 \t Episode: 318 \t Time_step: 99 \t Avg_reward: -4.92933252265 \t Cur_reward: -3.69565970624\n",
      "done\n",
      "Task : 0 \t Episode: 319 \t Time_step: 108 \t Avg_reward: -4.92042508577 \t Cur_reward: -3.13150141597\n",
      "Task : 0 \t Episode: 320 \t Time_step: 199 \t Avg_reward: -4.94095971819 \t Cur_reward: -6.49564275595\n",
      "done\n",
      "Task : 0 \t Episode: 321 \t Time_step: 61 \t Avg_reward: -4.93975498288 \t Cur_reward: -3.6136981732\n",
      "done\n",
      "Task : 0 \t Episode: 322 \t Time_step: 154 \t Avg_reward: -4.86541697778 \t Cur_reward: -3.94603807314\n",
      "done\n",
      "Task : 0 \t Episode: 323 \t Time_step: 150 \t Avg_reward: -4.84233921484 \t Cur_reward: -3.02726125562\n",
      "done\n",
      "Task : 0 \t Episode: 324 \t Time_step: 67 \t Avg_reward: -4.73957345184 \t Cur_reward: -3.25988750605\n",
      "Task : 0 \t Episode: 325 \t Time_step: 199 \t Avg_reward: -4.72058585828 \t Cur_reward: -10.438320057\n",
      "done\n",
      "Task : 0 \t Episode: 326 \t Time_step: 149 \t Avg_reward: -4.71410225577 \t Cur_reward: -4.4325436617\n",
      "Task : 0 \t Episode: 327 \t Time_step: 199 \t Avg_reward: -4.75137178876 \t Cur_reward: -8.24245930362\n",
      "done\n",
      "Task : 0 \t Episode: 328 \t Time_step: 146 \t Avg_reward: -4.78677800584 \t Cur_reward: -7.17061203821\n",
      "done\n",
      "Task : 0 \t Episode: 329 \t Time_step: 159 \t Avg_reward: -4.77990364883 \t Cur_reward: -4.48981064274\n",
      "done\n",
      "Task : 0 \t Episode: 330 \t Time_step: 110 \t Avg_reward: -4.76182974021 \t Cur_reward: -3.16244089857\n",
      "done\n",
      "Task : 0 \t Episode: 331 \t Time_step: 124 \t Avg_reward: -4.78642395205 \t Cur_reward: -4.60848178513\n",
      "done\n",
      "Task : 0 \t Episode: 332 \t Time_step: 125 \t Avg_reward: -4.78468680766 \t Cur_reward: -3.7650320095\n",
      "Task : 0 \t Episode: 333 \t Time_step: 199 \t Avg_reward: -4.83826043382 \t Cur_reward: -10.0199128194\n",
      "done\n",
      "Task : 0 \t Episode: 334 \t Time_step: 58 \t Avg_reward: -4.85122887692 \t Cur_reward: -4.45383661338\n",
      "done\n",
      "Task : 0 \t Episode: 335 \t Time_step: 145 \t Avg_reward: -4.83395707618 \t Cur_reward: -5.18796169578\n",
      "Task : 0 \t Episode: 336 \t Time_step: 199 \t Avg_reward: -4.86958286522 \t Cur_reward: -9.86527228951\n",
      "Task : 0 \t Episode: 337 \t Time_step: 199 \t Avg_reward: -4.91985398538 \t Cur_reward: -9.18899360116\n",
      "done\n",
      "Task : 0 \t Episode: 338 \t Time_step: 50 \t Avg_reward: -4.90651653279 \t Cur_reward: -2.34193403723\n",
      "done\n",
      "Task : 0 \t Episode: 339 \t Time_step: 150 \t Avg_reward: -4.86679620276 \t Cur_reward: -5.47112243767\n",
      "done\n",
      "Task : 0 \t Episode: 340 \t Time_step: 100 \t Avg_reward: -4.86336293464 \t Cur_reward: -3.64791170193\n",
      "done\n",
      "Task : 0 \t Episode: 341 \t Time_step: 55 \t Avg_reward: -4.85237857571 \t Cur_reward: -4.10305896767\n",
      "done\n",
      "Task : 0 \t Episode: 342 \t Time_step: 174 \t Avg_reward: -4.86264820343 \t Cur_reward: -3.5636624269\n",
      "done\n",
      "Task : 0 \t Episode: 343 \t Time_step: 151 \t Avg_reward: -4.84413822965 \t Cur_reward: -5.1940822153\n",
      "Task : 0 \t Episode: 344 \t Time_step: 199 \t Avg_reward: -4.81156938393 \t Cur_reward: -6.88605818135\n",
      "done\n",
      "Task : 0 \t Episode: 345 \t Time_step: 152 \t Avg_reward: -4.82848707178 \t Cur_reward: -6.64870068706\n",
      "done\n",
      "Task : 0 \t Episode: 346 \t Time_step: 148 \t Avg_reward: -4.83165093775 \t Cur_reward: -4.75066506508\n",
      "done\n",
      "Task : 0 \t Episode: 347 \t Time_step: 55 \t Avg_reward: -4.79344289382 \t Cur_reward: -3.2229311607\n",
      "done\n",
      "Task : 0 \t Episode: 348 \t Time_step: 51 \t Avg_reward: -4.76675062853 \t Cur_reward: -3.78278961678\n",
      "done\n",
      "Task : 0 \t Episode: 349 \t Time_step: 56 \t Avg_reward: -4.72567270155 \t Cur_reward: -4.04913672302\n",
      "done\n",
      "Task : 0 \t Episode: 350 \t Time_step: 145 \t Avg_reward: -4.73587351004 \t Cur_reward: -4.81508266923\n",
      "done\n",
      "Task : 0 \t Episode: 351 \t Time_step: 147 \t Avg_reward: -4.71233297636 \t Cur_reward: -5.46970725474\n",
      "done\n",
      "Task : 0 \t Episode: 352 \t Time_step: 143 \t Avg_reward: -4.68601529301 \t Cur_reward: -6.12921596073\n",
      "done\n",
      "Task : 0 \t Episode: 353 \t Time_step: 147 \t Avg_reward: -4.68530228277 \t Cur_reward: -5.19770412009\n",
      "done\n",
      "Task : 0 \t Episode: 354 \t Time_step: 177 \t Avg_reward: -4.71936022614 \t Cur_reward: -6.39064022066\n",
      "done\n",
      "Task : 0 \t Episode: 355 \t Time_step: 142 \t Avg_reward: -4.72798432529 \t Cur_reward: -5.87061584271\n",
      "done\n",
      "Task : 0 \t Episode: 356 \t Time_step: 174 \t Avg_reward: -4.7311747365 \t Cur_reward: -4.97020799096\n",
      "done\n",
      "Task : 0 \t Episode: 357 \t Time_step: 55 \t Avg_reward: -4.72435869804 \t Cur_reward: -2.98900225444\n",
      "done\n",
      "Task : 0 \t Episode: 358 \t Time_step: 60 \t Avg_reward: -4.71799697446 \t Cur_reward: -2.11673010832\n",
      "done\n",
      "Task : 0 \t Episode: 359 \t Time_step: 122 \t Avg_reward: -4.71301020165 \t Cur_reward: -3.5413459417\n",
      "done\n",
      "Task : 0 \t Episode: 360 \t Time_step: 184 \t Avg_reward: -4.73102294672 \t Cur_reward: -6.84489342409\n",
      "done\n",
      "Task : 0 \t Episode: 361 \t Time_step: 51 \t Avg_reward: -4.69320233581 \t Cur_reward: -2.51015936551\n",
      "done\n",
      "Task : 0 \t Episode: 362 \t Time_step: 136 \t Avg_reward: -4.70077544752 \t Cur_reward: -5.16454300588\n",
      "done\n",
      "Task : 0 \t Episode: 363 \t Time_step: 131 \t Avg_reward: -4.70647848485 \t Cur_reward: -4.84125560262\n",
      "done\n",
      "Task : 0 \t Episode: 364 \t Time_step: 117 \t Avg_reward: -4.71681186333 \t Cur_reward: -4.82261445287\n",
      "done\n",
      "Task : 0 \t Episode: 365 \t Time_step: 134 \t Avg_reward: -4.6984536512 \t Cur_reward: -4.15213220786\n",
      "done\n",
      "Task : 0 \t Episode: 366 \t Time_step: 173 \t Avg_reward: -4.73624841497 \t Cur_reward: -6.39447047853\n",
      "Task : 0 \t Episode: 367 \t Time_step: 199 \t Avg_reward: -4.81110858322 \t Cur_reward: -10.5868119628\n",
      "done\n",
      "Task : 0 \t Episode: 368 \t Time_step: 178 \t Avg_reward: -4.82085328601 \t Cur_reward: -7.17210186296\n",
      "Task : 0 \t Episode: 369 \t Time_step: 199 \t Avg_reward: -4.87294868931 \t Cur_reward: -9.17555746859\n",
      "Task : 0 \t Episode: 370 \t Time_step: 199 \t Avg_reward: -4.93708948374 \t Cur_reward: -11.7865334937\n",
      "Task : 0 \t Episode: 371 \t Time_step: 199 \t Avg_reward: -5.00942984981 \t Cur_reward: -10.6504909019\n",
      "Task : 0 \t Episode: 372 \t Time_step: 199 \t Avg_reward: -5.07648869275 \t Cur_reward: -9.80851380465\n",
      "Task : 0 \t Episode: 373 \t Time_step: 199 \t Avg_reward: -5.11646591069 \t Cur_reward: -8.61705029001\n",
      "Task : 0 \t Episode: 374 \t Time_step: 199 \t Avg_reward: -5.14594839123 \t Cur_reward: -7.36315300351\n",
      "Task : 0 \t Episode: 375 \t Time_step: 199 \t Avg_reward: -5.1609409749 \t Cur_reward: -8.52395433976\n",
      "Task : 0 \t Episode: 376 \t Time_step: 199 \t Avg_reward: -5.19959918156 \t Cur_reward: -8.1020577228\n",
      "Task : 0 \t Episode: 377 \t Time_step: 199 \t Avg_reward: -5.2394296744 \t Cur_reward: -7.63371620017\n",
      "Task : 0 \t Episode: 378 \t Time_step: 199 \t Avg_reward: -5.27601790803 \t Cur_reward: -7.14729262091\n",
      "done\n",
      "Task : 0 \t Episode: 379 \t Time_step: 122 \t Avg_reward: -5.30282488962 \t Cur_reward: -6.08613611438\n",
      "done\n",
      "Task : 0 \t Episode: 380 \t Time_step: 122 \t Avg_reward: -5.32400691338 \t Cur_reward: -5.77302479955\n",
      "Task : 0 \t Episode: 381 \t Time_step: 199 \t Avg_reward: -5.36815773975 \t Cur_reward: -8.09499881059\n",
      "Task : 0 \t Episode: 382 \t Time_step: 199 \t Avg_reward: -5.39689643552 \t Cur_reward: -7.51643281015\n",
      "Task : 0 \t Episode: 383 \t Time_step: 199 \t Avg_reward: -5.42752356198 \t Cur_reward: -7.21883202865\n",
      "Task : 0 \t Episode: 384 \t Time_step: 199 \t Avg_reward: -5.46540323776 \t Cur_reward: -6.66555419285\n",
      "Task : 0 \t Episode: 385 \t Time_step: 199 \t Avg_reward: -5.43609797058 \t Cur_reward: -6.81999530074\n",
      "Task : 0 \t Episode: 386 \t Time_step: 199 \t Avg_reward: -5.46547696785 \t Cur_reward: -7.12364554398\n",
      "done\n",
      "Task : 0 \t Episode: 387 \t Time_step: 56 \t Avg_reward: -5.45202585748 \t Cur_reward: -2.45519520481\n",
      "done\n",
      "Task : 0 \t Episode: 388 \t Time_step: 97 \t Avg_reward: -5.4499438425 \t Cur_reward: -4.186209845\n",
      "done\n",
      "Task : 0 \t Episode: 389 \t Time_step: 46 \t Avg_reward: -5.44667609092 \t Cur_reward: -3.28623460671\n",
      "done\n",
      "Task : 0 \t Episode: 390 \t Time_step: 50 \t Avg_reward: -5.42776707331 \t Cur_reward: -2.12891694969\n",
      "done\n",
      "Task : 0 \t Episode: 391 \t Time_step: 165 \t Avg_reward: -5.42002702576 \t Cur_reward: -4.30405176069\n",
      "done\n",
      "Task : 0 \t Episode: 392 \t Time_step: 110 \t Avg_reward: -5.3992068706 \t Cur_reward: -3.1697888469\n",
      "done\n",
      "Task : 0 \t Episode: 393 \t Time_step: 111 \t Avg_reward: -5.3917384899 \t Cur_reward: -3.58441094295\n",
      "Task : 0 \t Episode: 394 \t Time_step: 199 \t Avg_reward: -5.40149909899 \t Cur_reward: -5.25343368756\n",
      "done\n",
      "Task : 0 \t Episode: 395 \t Time_step: 128 \t Avg_reward: -5.40659633974 \t Cur_reward: -4.14699697873\n",
      "done\n",
      "Task : 0 \t Episode: 396 \t Time_step: 135 \t Avg_reward: -5.39284979986 \t Cur_reward: -4.74912739869\n",
      "done\n",
      "Task : 0 \t Episode: 397 \t Time_step: 84 \t Avg_reward: -5.36936247257 \t Cur_reward: -2.81528678098\n",
      "done\n",
      "Task : 0 \t Episode: 398 \t Time_step: 165 \t Avg_reward: -5.3769466767 \t Cur_reward: -4.53207740065\n",
      "Task : 0 \t Episode: 399 \t Time_step: 199 \t Avg_reward: -5.39645877182 \t Cur_reward: -6.09125674784\n",
      "done\n",
      "Task : 0 \t Episode: 400 \t Time_step: 150 \t Avg_reward: -5.40559052078 \t Cur_reward: -4.92471404706\n",
      "done\n",
      "Task : 0 \t Episode: 401 \t Time_step: 151 \t Avg_reward: -5.41665600561 \t Cur_reward: -4.61898467699\n",
      "Task : 0 \t Episode: 402 \t Time_step: 199 \t Avg_reward: -5.44017889116 \t Cur_reward: -5.90446634454\n",
      "Task : 0 \t Episode: 403 \t Time_step: 199 \t Avg_reward: -5.40866893164 \t Cur_reward: -4.49486508394\n",
      "Task : 0 \t Episode: 404 \t Time_step: 199 \t Avg_reward: -5.43970026031 \t Cur_reward: -6.59657404512\n",
      "Task : 0 \t Episode: 405 \t Time_step: 199 \t Avg_reward: -5.46163026449 \t Cur_reward: -5.69354375691\n",
      "Task : 0 \t Episode: 406 \t Time_step: 199 \t Avg_reward: -5.49324605875 \t Cur_reward: -8.1219559376\n",
      "Task : 0 \t Episode: 407 \t Time_step: 199 \t Avg_reward: -5.56116087961 \t Cur_reward: -11.042840441\n",
      "done\n",
      "Task : 0 \t Episode: 408 \t Time_step: 113 \t Avg_reward: -5.56641613529 \t Cur_reward: -6.58937149471\n",
      "done\n",
      "Task : 0 \t Episode: 409 \t Time_step: 112 \t Avg_reward: -5.58890312374 \t Cur_reward: -6.93367218791\n",
      "Task : 0 \t Episode: 410 \t Time_step: 199 \t Avg_reward: -5.64149224988 \t Cur_reward: -9.14912231383\n",
      "done\n",
      "Task : 0 \t Episode: 411 \t Time_step: 151 \t Avg_reward: -5.66091506671 \t Cur_reward: -5.68686516465\n",
      "Task : 0 \t Episode: 412 \t Time_step: 199 \t Avg_reward: -5.69061642776 \t Cur_reward: -5.99042292671\n",
      "Task : 0 \t Episode: 413 \t Time_step: 199 \t Avg_reward: -5.71937536136 \t Cur_reward: -8.17493488\n",
      "Task : 0 \t Episode: 414 \t Time_step: 199 \t Avg_reward: -5.73656721987 \t Cur_reward: -6.70383943549\n",
      "Task : 0 \t Episode: 415 \t Time_step: 199 \t Avg_reward: -5.75883258893 \t Cur_reward: -7.05411193386\n",
      "Task : 0 \t Episode: 416 \t Time_step: 199 \t Avg_reward: -5.79672063609 \t Cur_reward: -6.68441007748\n",
      "Task : 0 \t Episode: 417 \t Time_step: 199 \t Avg_reward: -5.82288399657 \t Cur_reward: -7.2771240623\n",
      "done\n",
      "Task : 0 \t Episode: 418 \t Time_step: 119 \t Avg_reward: -5.83315005866 \t Cur_reward: -4.72226591463\n",
      "Task : 0 \t Episode: 419 \t Time_step: 199 \t Avg_reward: -5.87450755834 \t Cur_reward: -7.26725138374\n",
      "Task : 0 \t Episode: 420 \t Time_step: 199 \t Avg_reward: -5.8677785655 \t Cur_reward: -5.82274347285\n",
      "Task : 0 \t Episode: 421 \t Time_step: 199 \t Avg_reward: -5.89080123605 \t Cur_reward: -5.9159652279\n",
      "Task : 0 \t Episode: 422 \t Time_step: 199 \t Avg_reward: -5.91302115256 \t Cur_reward: -6.16802972441\n",
      "Task : 0 \t Episode: 423 \t Time_step: 199 \t Avg_reward: -5.95432127339 \t Cur_reward: -7.1572733384\n",
      "Task : 0 \t Episode: 424 \t Time_step: 199 \t Avg_reward: -5.98964744664 \t Cur_reward: -6.79250483069\n",
      "Task : 0 \t Episode: 425 \t Time_step: 199 \t Avg_reward: -5.93889592221 \t Cur_reward: -5.36316761399\n",
      "Task : 0 \t Episode: 426 \t Time_step: 199 \t Avg_reward: -5.953456514 \t Cur_reward: -5.88860284136\n",
      "Task : 0 \t Episode: 427 \t Time_step: 199 \t Avg_reward: -5.93215547496 \t Cur_reward: -6.11235539907\n",
      "Task : 0 \t Episode: 428 \t Time_step: 199 \t Avg_reward: -5.91661354142 \t Cur_reward: -5.61641868415\n",
      "Task : 0 \t Episode: 429 \t Time_step: 199 \t Avg_reward: -5.94224264447 \t Cur_reward: -7.05272094768\n",
      "Task : 0 \t Episode: 430 \t Time_step: 199 \t Avg_reward: -5.9671228366 \t Cur_reward: -5.65046011202\n",
      "Task : 0 \t Episode: 431 \t Time_step: 199 \t Avg_reward: -5.98434812891 \t Cur_reward: -6.33101101624\n",
      "Task : 0 \t Episode: 432 \t Time_step: 199 \t Avg_reward: -6.00434807385 \t Cur_reward: -5.76502650318\n",
      "Task : 0 \t Episode: 433 \t Time_step: 199 \t Avg_reward: -5.95926800681 \t Cur_reward: -5.51190611573\n",
      "done\n",
      "Task : 0 \t Episode: 434 \t Time_step: 113 \t Avg_reward: -5.94338660627 \t Cur_reward: -2.86569655913\n",
      "Task : 0 \t Episode: 435 \t Time_step: 199 \t Avg_reward: -5.94767373861 \t Cur_reward: -5.61667493014\n",
      "done\n",
      "Task : 0 \t Episode: 436 \t Time_step: 69 \t Avg_reward: -5.88608570543 \t Cur_reward: -3.70646897095\n",
      "Task : 0 \t Episode: 437 \t Time_step: 199 \t Avg_reward: -5.84757740103 \t Cur_reward: -5.33816316082\n",
      "Task : 0 \t Episode: 438 \t Time_step: 199 \t Avg_reward: -5.88217737163 \t Cur_reward: -5.80193109777\n",
      "done\n",
      "Task : 0 \t Episode: 439 \t Time_step: 99 \t Avg_reward: -5.85572541411 \t Cur_reward: -2.8259266852\n",
      "Task : 0 \t Episode: 440 \t Time_step: 199 \t Avg_reward: -5.86178719405 \t Cur_reward: -4.25408969643\n",
      "done\n",
      "Task : 0 \t Episode: 441 \t Time_step: 56 \t Avg_reward: -5.85336617626 \t Cur_reward: -3.26095718808\n",
      "done\n",
      "Task : 0 \t Episode: 442 \t Time_step: 53 \t Avg_reward: -5.84779204343 \t Cur_reward: -3.00624914428\n",
      "Task : 0 \t Episode: 443 \t Time_step: 199 \t Avg_reward: -5.86564931177 \t Cur_reward: -6.97980904955\n",
      "Task : 0 \t Episode: 444 \t Time_step: 199 \t Avg_reward: -5.85112138766 \t Cur_reward: -5.43326576995\n",
      "done\n",
      "Task : 0 \t Episode: 445 \t Time_step: 86 \t Avg_reward: -5.81158398611 \t Cur_reward: -2.69496053219\n",
      "done\n",
      "Task : 0 \t Episode: 446 \t Time_step: 90 \t Avg_reward: -5.79596701844 \t Cur_reward: -3.18896829788\n",
      "Task : 0 \t Episode: 447 \t Time_step: 199 \t Avg_reward: -5.81341904756 \t Cur_reward: -4.96813407321\n",
      "done\n",
      "Task : 0 \t Episode: 448 \t Time_step: 85 \t Avg_reward: -5.8030120544 \t Cur_reward: -2.74209030025\n",
      "Task : 0 \t Episode: 449 \t Time_step: 199 \t Avg_reward: -5.81520344079 \t Cur_reward: -5.26827536222\n",
      "Task : 0 \t Episode: 450 \t Time_step: 199 \t Avg_reward: -5.82038588148 \t Cur_reward: -5.33332673808\n",
      "Task : 0 \t Episode: 451 \t Time_step: 199 \t Avg_reward: -5.83665136803 \t Cur_reward: -7.09625591044\n",
      "Task : 0 \t Episode: 452 \t Time_step: 199 \t Avg_reward: -5.85559221596 \t Cur_reward: -8.02330075323\n",
      "Task : 0 \t Episode: 453 \t Time_step: 199 \t Avg_reward: -5.87300986806 \t Cur_reward: -6.93946933011\n",
      "Task : 0 \t Episode: 454 \t Time_step: 199 \t Avg_reward: -5.87443512833 \t Cur_reward: -6.53316624807\n",
      "Task : 0 \t Episode: 455 \t Time_step: 199 \t Avg_reward: -5.87589632905 \t Cur_reward: -6.01673591468\n",
      "Task : 0 \t Episode: 456 \t Time_step: 199 \t Avg_reward: -5.87818070466 \t Cur_reward: -5.19864555159\n",
      "Task : 0 \t Episode: 457 \t Time_step: 199 \t Avg_reward: -5.9274365901 \t Cur_reward: -7.91459079845\n",
      "Task : 0 \t Episode: 458 \t Time_step: 199 \t Avg_reward: -5.98643612765 \t Cur_reward: -8.01668386313\n",
      "Task : 0 \t Episode: 459 \t Time_step: 199 \t Avg_reward: -6.0350437907 \t Cur_reward: -8.40211224647\n",
      "Task : 0 \t Episode: 460 \t Time_step: 199 \t Avg_reward: -6.03516536159 \t Cur_reward: -6.85705051367\n",
      "Task : 0 \t Episode: 461 \t Time_step: 199 \t Avg_reward: -6.07239655664 \t Cur_reward: -6.2332788702\n",
      "Task : 0 \t Episode: 462 \t Time_step: 199 \t Avg_reward: -6.10906958216 \t Cur_reward: -8.8318455585\n",
      "Task : 0 \t Episode: 463 \t Time_step: 199 \t Avg_reward: -6.14127824282 \t Cur_reward: -8.06212166822\n",
      "Task : 0 \t Episode: 464 \t Time_step: 199 \t Avg_reward: -6.18419741525 \t Cur_reward: -9.11453169561\n",
      "done\n",
      "Task : 0 \t Episode: 465 \t Time_step: 41 \t Avg_reward: -6.17550113039 \t Cur_reward: -3.28250372173\n",
      "done\n",
      "Task : 0 \t Episode: 466 \t Time_step: 88 \t Avg_reward: -6.15739853071 \t Cur_reward: -4.58421051053\n",
      "done\n",
      "Task : 0 \t Episode: 467 \t Time_step: 104 \t Avg_reward: -6.10634556994 \t Cur_reward: -5.48151588598\n",
      "Task : 0 \t Episode: 468 \t Time_step: 199 \t Avg_reward: -6.12284472821 \t Cur_reward: -8.82201769057\n",
      "Task : 0 \t Episode: 469 \t Time_step: 199 \t Avg_reward: -6.10464321911 \t Cur_reward: -7.35540655846\n",
      "Task : 0 \t Episode: 470 \t Time_step: 199 \t Avg_reward: -6.09785718511 \t Cur_reward: -11.1079300937\n",
      "Task : 0 \t Episode: 471 \t Time_step: 199 \t Avg_reward: -6.08948281656 \t Cur_reward: -9.81305404668\n",
      "Task : 0 \t Episode: 472 \t Time_step: 199 \t Avg_reward: -6.07933762876 \t Cur_reward: -8.7939950248\n",
      "Task : 0 \t Episode: 473 \t Time_step: 199 \t Avg_reward: -6.07925058714 \t Cur_reward: -8.6083461272\n",
      "Task : 0 \t Episode: 474 \t Time_step: 199 \t Avg_reward: -6.07851711663 \t Cur_reward: -7.28980595315\n",
      "Task : 0 \t Episode: 475 \t Time_step: 199 \t Avg_reward: -6.05178791642 \t Cur_reward: -5.85103431807\n",
      "done\n",
      "Task : 0 \t Episode: 476 \t Time_step: 96 \t Avg_reward: -6.00854017289 \t Cur_reward: -3.77728337042\n",
      "Task : 0 \t Episode: 477 \t Time_step: 199 \t Avg_reward: -6.00529128394 \t Cur_reward: -7.30882730532\n",
      "Task : 0 \t Episode: 478 \t Time_step: 199 \t Avg_reward: -6.00539583497 \t Cur_reward: -7.15774772398\n",
      "Task : 0 \t Episode: 479 \t Time_step: 199 \t Avg_reward: -6.03268003175 \t Cur_reward: -8.81455579241\n",
      "Task : 0 \t Episode: 480 \t Time_step: 199 \t Avg_reward: -6.06970625278 \t Cur_reward: -9.4756469024\n",
      "Task : 0 \t Episode: 481 \t Time_step: 199 \t Avg_reward: -6.09393285703 \t Cur_reward: -10.5176592354\n",
      "Task : 0 \t Episode: 482 \t Time_step: 199 \t Avg_reward: -6.13478111501 \t Cur_reward: -11.6012586079\n",
      "Task : 0 \t Episode: 483 \t Time_step: 199 \t Avg_reward: -6.14527631085 \t Cur_reward: -8.26835161315\n",
      "Task : 0 \t Episode: 484 \t Time_step: 199 \t Avg_reward: -6.16858346122 \t Cur_reward: -8.99626922916\n",
      "Task : 0 \t Episode: 485 \t Time_step: 199 \t Avg_reward: -6.17464149298 \t Cur_reward: -7.4257984767\n",
      "Task : 0 \t Episode: 486 \t Time_step: 199 \t Avg_reward: -6.18483086455 \t Cur_reward: -8.14258270141\n",
      "Task : 0 \t Episode: 487 \t Time_step: 199 \t Avg_reward: -6.23447506319 \t Cur_reward: -7.41961506911\n",
      "Task : 0 \t Episode: 488 \t Time_step: 199 \t Avg_reward: -6.25203273582 \t Cur_reward: -5.94197710799\n",
      "Task : 0 \t Episode: 489 \t Time_step: 199 \t Avg_reward: -6.28438193892 \t Cur_reward: -6.52115491653\n",
      "Task : 0 \t Episode: 490 \t Time_step: 199 \t Avg_reward: -6.33981092065 \t Cur_reward: -7.67181512275\n",
      "done\n",
      "Task : 0 \t Episode: 491 \t Time_step: 94 \t Avg_reward: -6.32323093565 \t Cur_reward: -2.64605326086\n",
      "Task : 0 \t Episode: 492 \t Time_step: 199 \t Avg_reward: -6.35095705879 \t Cur_reward: -5.94240116022\n",
      "Task : 0 \t Episode: 493 \t Time_step: 199 \t Avg_reward: -6.36451325733 \t Cur_reward: -4.94003079772\n",
      "Task : 0 \t Episode: 494 \t Time_step: 199 \t Avg_reward: -6.37250944277 \t Cur_reward: -6.05305223082\n",
      "Task : 0 \t Episode: 495 \t Time_step: 199 \t Avg_reward: -6.41035603172 \t Cur_reward: -7.93165587435\n",
      "Task : 0 \t Episode: 496 \t Time_step: 199 \t Avg_reward: -6.44577462411 \t Cur_reward: -8.29098663769\n",
      "done\n",
      "Task : 0 \t Episode: 497 \t Time_step: 95 \t Avg_reward: -6.45190197753 \t Cur_reward: -3.4280221223\n",
      "Task : 0 \t Episode: 498 \t Time_step: 199 \t Avg_reward: -6.4607012864 \t Cur_reward: -5.4120082885\n",
      "Task : 0 \t Episode: 499 \t Time_step: 199 \t Avg_reward: -6.46590497914 \t Cur_reward: -6.61162602116\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_recorded_paras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-79e6d5757bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0msummary_avg_reward_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_avg_reward_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mrecord_paras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'actor_target'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mall_recorded_paras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_paras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_recorded_paras' is not defined"
     ]
    }
   ],
   "source": [
    "for j in range(len(goal_pos)-49):\n",
    "    env.set_goal(np.append(goal_pos[j], [0,0]))\n",
    "    all_sum_reward_list = []\n",
    "    all_avg_reward_list = []\n",
    "    all_reward_list = []\n",
    "    all_loss_list = []\n",
    "    all_t_list = []\n",
    "    \n",
    "    for i in range(MAX_EPISODE):\n",
    "\n",
    "        state = env.reset()\n",
    "        noise.reset()\n",
    "        reward_list = []\n",
    "        loss_list = []\n",
    "\n",
    "        for t in range(MAX_TIME):\n",
    "            action = actor.predict(np.reshape(state, (-1, state_dim))) \n",
    "            action += noise.noise()\n",
    "            action = np.clip(action, -action_bound, action_bound)\n",
    "            action = np.reshape(action, action_dim)\n",
    "\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            replay_buffer.add_sample(np.reshape(state, state_dim), \\\n",
    "                                     np.reshape(action,action_dim),\\\n",
    "                                     reward,\\\n",
    "                                     np.reshape(next_state,state_dim),\\\n",
    "                                     done)\n",
    "\n",
    "            mini_batch = replay_buffer.rand_sample(batch_size = BATCH_SIZE, seed = RANDOM_SEED + t + i*MAX_TIME)\n",
    "            s_batch, a_batch, r_batch, s2_batch, t_batch = mini_batch\n",
    "\n",
    "            a2_batch = actor.predict(s2_batch, if_target = True)\n",
    "            training_q = r_batch + GAMMA * critic.predict(s2_batch, a2_batch, if_target = True) #* ~t_batch\n",
    "\n",
    "            _, loss = critic.train(s_batch, a_batch, training_q)\n",
    "\n",
    "            train_action_batch = actor.predict(s_batch)\n",
    "            critic_grad = critic.compute_critic_gradient(s_batch, train_action_batch)\n",
    "            actor.train(s_batch, critic_grad[0])\n",
    "\n",
    "            actor.update_target_network()\n",
    "            critic.update_target_network()\n",
    "\n",
    "            reward_list.append(reward)\n",
    "            loss_list.append(loss)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    #         print('Episode: %s \\t Action: %s, %s \\t State: %s,%s,%s,%s' %(i, action[0], action[1], state[0],state[1],state[2],state[3]))\n",
    "\n",
    "        all_sum_reward_list.append(np.sum(reward_list))\n",
    "        all_avg_reward_list.append(np.mean(all_sum_reward_list[-100:]))\n",
    "        all_reward_list.append(reward_list)\n",
    "        all_loss_list.append(loss_list)\n",
    "        all_t_list.append(t)\n",
    "\n",
    "        print('Task : %s \\t Episode: %s \\t Time_step: %s \\t Avg_reward: %s \\t Cur_reward: %s'%(j, i, t, all_avg_reward_list[-1], all_sum_reward_list[-1]))\n",
    "    \n",
    "    summary_sum_reward_list[j] = np.array(all_sum_reward_list)\n",
    "    summary_avg_reward_list[j] = np.array(all_avg_reward_list)\n",
    "    record_paras = [v for v in tf.trainable_variables() if 'actor_target' in v.name]\n",
    "    all_recorded_paras.append(sess.run(record_paras))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n",
      "(501, 50)\n",
      "(2, 2)\n",
      "(10, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "[print(v.shape) for v in U]\n",
    "print(S.shape)\n",
    "\n",
    "test = np.tensordot(S, U[1], axes = (1,-1))\n",
    "print(test.shape)\n",
    "\n",
    "test2 = np.tensordot(test, U[2], axes = (1,-1))\n",
    "print(test2.shape)\n",
    "\n",
    "test3 = np.array([ np.sum(np.array([ U[0][v][i]*test2[i]  for i in range(10)]), axis = 0) for v in range(50)])\n",
    "# test3 = np.tensordot(test2,U[0], axes = (-1,0))\n",
    "# print(test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(all_avg_reward_list)\n",
    "plt.plot(all_sum_reward_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
