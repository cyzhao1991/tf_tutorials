{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from actor import ActorNetwork\n",
    "from rbfActor import RbfActorNetwork\n",
    "from actorls import ActorLSNetwork\n",
    "from critic import CriticNetwork\n",
    "from replay_buffer import ReplayBuffer\n",
    "from ounoise import OUNoise\n",
    "import gym, time\n",
    "from Envs.reaching import ReachingEnv\n",
    "from Envs.throwing import ThrowingEnv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensor_toolbox_yyang as ttool\n",
    "\n",
    "MAX_EPISODE = 500\n",
    "MAX_TIME = 200\n",
    "\n",
    "ACTOR_LEARNING_RATE = 0.0001\n",
    "CRITIC_LEARNING_RATE = 0.001\n",
    "L2_DECAY = 0.01\n",
    "GAMMA = 0.99\n",
    "TAU = 0.001\n",
    "\n",
    "BUFFER_SIZE = 1000000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "OU_MU = 0.0\n",
    "OU_THETA = 0.15  \n",
    "OU_SIGMA = 0.20\n",
    "\n",
    "RANDOM_SEED = 1926\n",
    "\n",
    "goal_pos = np.load('./Envs/reaching_goal_pos.npy')\n",
    "source_paras = np.load('./Data/reaching_ddpg_rbf_500.npz')\n",
    "\n",
    "GAMMA = .99\n",
    "# env = gym.make('Pendulum-v0')\n",
    "env = ReachingEnv(include_t = True)\n",
    "# env = ThrowingEnv(include_t = True)\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_bound = env.action_space.high\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 501) (501, 2)\n",
      "(?, 501) (501, 2)\n"
     ]
    }
   ],
   "source": [
    "actor = ActorLSNetwork(sess, state_dim, action_dim, action_bound, L_init = None, S_init = None, \\\n",
    "                         seed = RANDOM_SEED, tau = TAU, learning_rate = ACTOR_LEARNING_RATE)\n",
    "\n",
    "critic = CriticNetwork(sess, state_dim, action_dim, hidden_layer_dim = [30],\\\n",
    "                       l2_alpha = L2_DECAY, seed = RANDOM_SEED, tau =TAU, learning_rate = CRITIC_LEARNING_RATE)\n",
    "replay_buffer = ReplayBuffer(BUFFER_SIZE, RANDOM_SEED)\n",
    "noise = OUNoise(action_dim, mu = OU_MU, theta = OU_THETA, sigma = OU_SIGMA, seed = RANDOM_SEED)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "summary_sum_reward_list = np.zeros([50,MAX_EPISODE])\n",
    "summary_avg_reward_list = np.zeros([50,MAX_EPISODE])\n",
    "all_recorded_actor_paras = []\n",
    "all_recorded_critic_paras = []\n",
    "all_weights = np.array([v[0] for v in source_paras['arr_0']])\n",
    "rank = [10,50,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task : 9 \t Episode: 0 \t Time_step: 199 \t Avg_reward: -131.86109 \t Cur_reward: -131.86109\n",
      "Task : 9 \t Episode: 1 \t Time_step: 199 \t Avg_reward: -157.39538 \t Cur_reward: -182.92966\n",
      "Task : 9 \t Episode: 2 \t Time_step: 199 \t Avg_reward: -163.51305 \t Cur_reward: -175.74840\n",
      "Task : 9 \t Episode: 3 \t Time_step: 199 \t Avg_reward: -169.76370 \t Cur_reward: -188.51564\n",
      "Task : 9 \t Episode: 4 \t Time_step: 199 \t Avg_reward: -173.66153 \t Cur_reward: -189.25286\n",
      "Task : 9 \t Episode: 5 \t Time_step: 199 \t Avg_reward: -176.43149 \t Cur_reward: -190.28130\n",
      "Task : 9 \t Episode: 6 \t Time_step: 199 \t Avg_reward: -178.47173 \t Cur_reward: -190.71316\n",
      "Task : 9 \t Episode: 7 \t Time_step: 199 \t Avg_reward: -179.82729 \t Cur_reward: -189.31620\n",
      "Task : 9 \t Episode: 8 \t Time_step: 199 \t Avg_reward: -180.86534 \t Cur_reward: -189.16977\n",
      "Task : 9 \t Episode: 9 \t Time_step: 199 \t Avg_reward: -181.69159 \t Cur_reward: -189.12782\n",
      "Task : 9 \t Episode: 10 \t Time_step: 199 \t Avg_reward: -182.33836 \t Cur_reward: -188.80606\n",
      "Task : 9 \t Episode: 11 \t Time_step: 199 \t Avg_reward: -182.89117 \t Cur_reward: -188.97208\n",
      "Task : 9 \t Episode: 12 \t Time_step: 199 \t Avg_reward: -183.33332 \t Cur_reward: -188.63911\n",
      "Task : 9 \t Episode: 13 \t Time_step: 199 \t Avg_reward: -183.71673 \t Cur_reward: -188.70108\n",
      "Task : 9 \t Episode: 14 \t Time_step: 199 \t Avg_reward: -183.96022 \t Cur_reward: -187.36899\n",
      "Task : 9 \t Episode: 15 \t Time_step: 199 \t Avg_reward: -184.16697 \t Cur_reward: -187.26823\n",
      "Task : 9 \t Episode: 16 \t Time_step: 199 \t Avg_reward: -184.39299 \t Cur_reward: -188.00938\n",
      "Task : 9 \t Episode: 17 \t Time_step: 199 \t Avg_reward: -184.54851 \t Cur_reward: -187.19225\n",
      "Task : 9 \t Episode: 18 \t Time_step: 199 \t Avg_reward: -184.71960 \t Cur_reward: -187.79926\n",
      "Task : 9 \t Episode: 19 \t Time_step: 199 \t Avg_reward: -184.83154 \t Cur_reward: -186.95835\n",
      "Task : 9 \t Episode: 20 \t Time_step: 199 \t Avg_reward: -184.97631 \t Cur_reward: -187.87179\n",
      "Task : 9 \t Episode: 21 \t Time_step: 199 \t Avg_reward: -185.09188 \t Cur_reward: -187.51882\n",
      "Task : 9 \t Episode: 22 \t Time_step: 199 \t Avg_reward: -184.33034 \t Cur_reward: -167.57645\n",
      "Task : 9 \t Episode: 23 \t Time_step: 199 \t Avg_reward: -183.20842 \t Cur_reward: -157.40430\n",
      "Task : 9 \t Episode: 24 \t Time_step: 199 \t Avg_reward: -182.21457 \t Cur_reward: -158.36227\n",
      "Task : 9 \t Episode: 25 \t Time_step: 199 \t Avg_reward: -181.28923 \t Cur_reward: -158.15553\n",
      "Task : 9 \t Episode: 26 \t Time_step: 199 \t Avg_reward: -180.43599 \t Cur_reward: -158.25179\n",
      "Task : 9 \t Episode: 27 \t Time_step: 199 \t Avg_reward: -179.65792 \t Cur_reward: -158.65008\n",
      "Task : 9 \t Episode: 28 \t Time_step: 199 \t Avg_reward: -179.01018 \t Cur_reward: -160.87355\n",
      "Task : 9 \t Episode: 29 \t Time_step: 199 \t Avg_reward: -178.20348 \t Cur_reward: -154.80898\n",
      "Task : 9 \t Episode: 30 \t Time_step: 199 \t Avg_reward: -177.32019 \t Cur_reward: -150.82149\n",
      "Task : 9 \t Episode: 31 \t Time_step: 199 \t Avg_reward: -176.72029 \t Cur_reward: -158.12353\n",
      "Task : 9 \t Episode: 32 \t Time_step: 199 \t Avg_reward: -176.24275 \t Cur_reward: -160.96160\n",
      "Task : 9 \t Episode: 33 \t Time_step: 199 \t Avg_reward: -175.90316 \t Cur_reward: -164.69655\n",
      "Task : 9 \t Episode: 34 \t Time_step: 199 \t Avg_reward: -175.52320 \t Cur_reward: -162.60458\n",
      "Task : 9 \t Episode: 35 \t Time_step: 199 \t Avg_reward: -174.94535 \t Cur_reward: -154.72069\n",
      "Task : 9 \t Episode: 36 \t Time_step: 199 \t Avg_reward: -174.13278 \t Cur_reward: -144.88010\n",
      "Task : 9 \t Episode: 37 \t Time_step: 199 \t Avg_reward: -173.57380 \t Cur_reward: -152.89176\n",
      "Task : 9 \t Episode: 38 \t Time_step: 199 \t Avg_reward: -173.03318 \t Cur_reward: -152.48928\n",
      "Task : 9 \t Episode: 39 \t Time_step: 199 \t Avg_reward: -172.52264 \t Cur_reward: -152.61175\n",
      "Task : 9 \t Episode: 40 \t Time_step: 199 \t Avg_reward: -172.04500 \t Cur_reward: -152.93953\n",
      "Task : 9 \t Episode: 41 \t Time_step: 199 \t Avg_reward: -171.55157 \t Cur_reward: -151.32086\n",
      "Task : 9 \t Episode: 42 \t Time_step: 199 \t Avg_reward: -171.09988 \t Cur_reward: -152.12873\n",
      "Task : 9 \t Episode: 43 \t Time_step: 199 \t Avg_reward: -170.62862 \t Cur_reward: -150.36450\n",
      "Task : 9 \t Episode: 44 \t Time_step: 199 \t Avg_reward: -170.21348 \t Cur_reward: -151.94724\n",
      "Task : 9 \t Episode: 45 \t Time_step: 199 \t Avg_reward: -169.82890 \t Cur_reward: -152.52295\n",
      "Task : 9 \t Episode: 46 \t Time_step: 199 \t Avg_reward: -169.47436 \t Cur_reward: -153.16558\n",
      "Task : 9 \t Episode: 47 \t Time_step: 199 \t Avg_reward: -169.07539 \t Cur_reward: -150.32352\n",
      "Task : 9 \t Episode: 48 \t Time_step: 199 \t Avg_reward: -168.44568 \t Cur_reward: -138.21972\n",
      "Task : 9 \t Episode: 49 \t Time_step: 199 \t Avg_reward: -167.77284 \t Cur_reward: -134.80360\n",
      "Task : 9 \t Episode: 50 \t Time_step: 199 \t Avg_reward: -167.05022 \t Cur_reward: -130.91933\n",
      "Task : 9 \t Episode: 51 \t Time_step: 199 \t Avg_reward: -166.31637 \t Cur_reward: -128.88996\n",
      "Task : 9 \t Episode: 52 \t Time_step: 199 \t Avg_reward: -165.56714 \t Cur_reward: -126.60714\n",
      "Task : 9 \t Episode: 53 \t Time_step: 199 \t Avg_reward: -164.85525 \t Cur_reward: -127.12508\n",
      "Task : 9 \t Episode: 54 \t Time_step: 199 \t Avg_reward: -164.18772 \t Cur_reward: -128.14101\n",
      "Task : 9 \t Episode: 55 \t Time_step: 199 \t Avg_reward: -163.54582 \t Cur_reward: -128.24168\n",
      "Task : 9 \t Episode: 56 \t Time_step: 199 \t Avg_reward: -162.78680 \t Cur_reward: -120.28133\n",
      "Task : 9 \t Episode: 57 \t Time_step: 199 \t Avg_reward: -161.98357 \t Cur_reward: -116.19976\n",
      "Task : 9 \t Episode: 58 \t Time_step: 199 \t Avg_reward: -161.21800 \t Cur_reward: -116.81489\n",
      "Task : 9 \t Episode: 59 \t Time_step: 199 \t Avg_reward: -160.36549 \t Cur_reward: -110.06740\n",
      "Task : 9 \t Episode: 60 \t Time_step: 199 \t Avg_reward: -159.50408 \t Cur_reward: -107.81974\n",
      "Task : 9 \t Episode: 61 \t Time_step: 199 \t Avg_reward: -158.59449 \t Cur_reward: -103.10932\n",
      "Task : 9 \t Episode: 62 \t Time_step: 199 \t Avg_reward: -157.72130 \t Cur_reward: -103.58364\n",
      "Task : 9 \t Episode: 63 \t Time_step: 199 \t Avg_reward: -156.72419 \t Cur_reward: -93.90588\n",
      "Task : 9 \t Episode: 64 \t Time_step: 199 \t Avg_reward: -155.81356 \t Cur_reward: -97.53329\n",
      "Task : 9 \t Episode: 65 \t Time_step: 199 \t Avg_reward: -154.90837 \t Cur_reward: -96.07130\n",
      "Task : 9 \t Episode: 66 \t Time_step: 199 \t Avg_reward: -154.01119 \t Cur_reward: -94.79746\n",
      "Task : 9 \t Episode: 67 \t Time_step: 199 \t Avg_reward: -153.10588 \t Cur_reward: -92.44998\n",
      "Task : 9 \t Episode: 68 \t Time_step: 199 \t Avg_reward: -152.02768 \t Cur_reward: -78.70980\n",
      "Task : 9 \t Episode: 69 \t Time_step: 199 \t Avg_reward: -150.86448 \t Cur_reward: -70.60384\n",
      "Task : 9 \t Episode: 70 \t Time_step: 199 \t Avg_reward: -149.70791 \t Cur_reward: -68.74795\n",
      "Task : 9 \t Episode: 71 \t Time_step: 199 \t Avg_reward: -148.67494 \t Cur_reward: -75.33394\n",
      "Task : 9 \t Episode: 72 \t Time_step: 199 \t Avg_reward: -147.58797 \t Cur_reward: -69.32635\n",
      "Task : 9 \t Episode: 73 \t Time_step: 199 \t Avg_reward: -146.51546 \t Cur_reward: -68.22241\n",
      "Task : 9 \t Episode: 74 \t Time_step: 199 \t Avg_reward: -145.48388 \t Cur_reward: -69.14682\n",
      "Task : 9 \t Episode: 75 \t Time_step: 199 \t Avg_reward: -144.46743 \t Cur_reward: -68.23356\n",
      "Task : 9 \t Episode: 76 \t Time_step: 199 \t Avg_reward: -143.50369 \t Cur_reward: -70.25978\n",
      "Task : 9 \t Episode: 77 \t Time_step: 199 \t Avg_reward: -142.55282 \t Cur_reward: -69.33569\n",
      "Task : 9 \t Episode: 78 \t Time_step: 199 \t Avg_reward: -141.63846 \t Cur_reward: -70.31788\n",
      "Task : 9 \t Episode: 79 \t Time_step: 199 \t Avg_reward: -140.77191 \t Cur_reward: -72.31494\n",
      "Task : 9 \t Episode: 80 \t Time_step: 199 \t Avg_reward: -139.89194 \t Cur_reward: -69.49450\n",
      "Task : 9 \t Episode: 81 \t Time_step: 199 \t Avg_reward: -139.05304 \t Cur_reward: -71.10201\n",
      "Task : 9 \t Episode: 82 \t Time_step: 199 \t Avg_reward: -138.18711 \t Cur_reward: -67.18034\n",
      "Task : 9 \t Episode: 83 \t Time_step: 199 \t Avg_reward: -137.37889 \t Cur_reward: -70.29725\n",
      "Task : 9 \t Episode: 84 \t Time_step: 199 \t Avg_reward: -136.55206 \t Cur_reward: -67.09820\n",
      "Task : 9 \t Episode: 85 \t Time_step: 199 \t Avg_reward: -135.74076 \t Cur_reward: -66.78017\n",
      "Task : 9 \t Episode: 86 \t Time_step: 199 \t Avg_reward: -134.96529 \t Cur_reward: -68.27472\n",
      "Task : 9 \t Episode: 87 \t Time_step: 199 \t Avg_reward: -134.24648 \t Cur_reward: -71.70993\n",
      "Task : 9 \t Episode: 88 \t Time_step: 199 \t Avg_reward: -133.52743 \t Cur_reward: -70.25094\n",
      "Task : 9 \t Episode: 89 \t Time_step: 199 \t Avg_reward: -132.84823 \t Cur_reward: -72.39932\n",
      "Task : 9 \t Episode: 90 \t Time_step: 199 \t Avg_reward: -132.14472 \t Cur_reward: -68.82935\n",
      "Task : 9 \t Episode: 91 \t Time_step: 199 \t Avg_reward: -131.44739 \t Cur_reward: -67.99060\n",
      "Task : 9 \t Episode: 92 \t Time_step: 199 \t Avg_reward: -130.74410 \t Cur_reward: -66.04118\n",
      "Task : 9 \t Episode: 93 \t Time_step: 199 \t Avg_reward: -130.06465 \t Cur_reward: -66.87601\n",
      "Task : 9 \t Episode: 94 \t Time_step: 199 \t Avg_reward: -129.39101 \t Cur_reward: -66.06859\n",
      "Task : 9 \t Episode: 95 \t Time_step: 199 \t Avg_reward: -128.68489 \t Cur_reward: -61.60341\n",
      "Task : 9 \t Episode: 96 \t Time_step: 199 \t Avg_reward: -128.02308 \t Cur_reward: -64.48880\n",
      "Task : 9 \t Episode: 97 \t Time_step: 199 \t Avg_reward: -127.35941 \t Cur_reward: -62.98417\n",
      "Task : 9 \t Episode: 98 \t Time_step: 199 \t Avg_reward: -126.76792 \t Cur_reward: -68.80123\n",
      "Task : 9 \t Episode: 99 \t Time_step: 199 \t Avg_reward: -126.14850 \t Cur_reward: -64.82589\n",
      "Task : 9 \t Episode: 100 \t Time_step: 199 \t Avg_reward: -125.46578 \t Cur_reward: -63.58996\n",
      "Task : 9 \t Episode: 101 \t Time_step: 199 \t Avg_reward: -124.26666 \t Cur_reward: -63.01729\n",
      "Task : 9 \t Episode: 102 \t Time_step: 199 \t Avg_reward: -123.12951 \t Cur_reward: -62.03306\n",
      "Task : 9 \t Episode: 103 \t Time_step: 199 \t Avg_reward: -121.88029 \t Cur_reward: -63.59437\n",
      "Task : 9 \t Episode: 104 \t Time_step: 199 \t Avg_reward: -120.61008 \t Cur_reward: -62.23133\n",
      "Task : 9 \t Episode: 105 \t Time_step: 199 \t Avg_reward: -119.36618 \t Cur_reward: -65.89095\n",
      "Task : 9 \t Episode: 106 \t Time_step: 199 \t Avg_reward: -118.08381 \t Cur_reward: -62.47675\n",
      "Task : 9 \t Episode: 107 \t Time_step: 199 \t Avg_reward: -116.81204 \t Cur_reward: -62.13931\n",
      "Task : 9 \t Episode: 108 \t Time_step: 199 \t Avg_reward: -115.54758 \t Cur_reward: -62.72374\n",
      "Task : 9 \t Episode: 109 \t Time_step: 199 \t Avg_reward: -114.29041 \t Cur_reward: -63.41056\n",
      "Task : 9 \t Episode: 110 \t Time_step: 199 \t Avg_reward: -113.03008 \t Cur_reward: -62.77290\n",
      "Task : 9 \t Episode: 111 \t Time_step: 199 \t Avg_reward: -111.80073 \t Cur_reward: -66.03754\n",
      "Task : 9 \t Episode: 112 \t Time_step: 199 \t Avg_reward: -110.51964 \t Cur_reward: -60.53010\n",
      "Task : 9 \t Episode: 113 \t Time_step: 199 \t Avg_reward: -109.23696 \t Cur_reward: -60.43241\n",
      "Task : 9 \t Episode: 114 \t Time_step: 199 \t Avg_reward: -107.98099 \t Cur_reward: -61.77268\n",
      "Task : 9 \t Episode: 115 \t Time_step: 199 \t Avg_reward: -106.72012 \t Cur_reward: -61.18102\n",
      "Task : 9 \t Episode: 116 \t Time_step: 199 \t Avg_reward: -105.47356 \t Cur_reward: -63.35307\n",
      "Task : 9 \t Episode: 117 \t Time_step: 199 \t Avg_reward: -104.22646 \t Cur_reward: -62.48278\n",
      "Task : 9 \t Episode: 118 \t Time_step: 199 \t Avg_reward: -102.96163 \t Cur_reward: -61.31613\n",
      "Task : 9 \t Episode: 119 \t Time_step: 199 \t Avg_reward: -101.69916 \t Cur_reward: -60.71139\n",
      "Task : 9 \t Episode: 120 \t Time_step: 199 \t Avg_reward: -100.44293 \t Cur_reward: -62.24841\n",
      "Task : 9 \t Episode: 121 \t Time_step: 199 \t Avg_reward: -99.20040 \t Cur_reward: -63.26584\n",
      "Task : 9 \t Episode: 122 \t Time_step: 199 \t Avg_reward: -98.16231 \t Cur_reward: -63.76736\n",
      "Task : 9 \t Episode: 123 \t Time_step: 199 \t Avg_reward: -97.20611 \t Cur_reward: -61.78427\n",
      "Task : 9 \t Episode: 124 \t Time_step: 199 \t Avg_reward: -96.25215 \t Cur_reward: -62.96650\n",
      "Task : 9 \t Episode: 125 \t Time_step: 199 \t Avg_reward: -95.29241 \t Cur_reward: -62.18189\n",
      "Task : 9 \t Episode: 126 \t Time_step: 199 \t Avg_reward: -94.33936 \t Cur_reward: -62.94630\n",
      "Task : 9 \t Episode: 127 \t Time_step: 199 \t Avg_reward: -93.36251 \t Cur_reward: -60.96522\n",
      "Task : 9 \t Episode: 128 \t Time_step: 199 \t Avg_reward: -92.38259 \t Cur_reward: -62.88193\n",
      "Task : 9 \t Episode: 129 \t Time_step: 199 \t Avg_reward: -91.46625 \t Cur_reward: -63.17495\n",
      "Task : 9 \t Episode: 130 \t Time_step: 199 \t Avg_reward: -90.59342 \t Cur_reward: -63.53840\n",
      "Task : 9 \t Episode: 131 \t Time_step: 199 \t Avg_reward: -89.61270 \t Cur_reward: -60.05136\n",
      "Task : 9 \t Episode: 132 \t Time_step: 199 \t Avg_reward: -88.62622 \t Cur_reward: -62.31366\n",
      "Task : 9 \t Episode: 133 \t Time_step: 199 \t Avg_reward: -87.61333 \t Cur_reward: -63.40768\n",
      "Task : 9 \t Episode: 134 \t Time_step: 199 \t Avg_reward: -86.63163 \t Cur_reward: -64.43419\n",
      "Task : 9 \t Episode: 135 \t Time_step: 199 \t Avg_reward: -85.72043 \t Cur_reward: -63.60076\n",
      "Task : 9 \t Episode: 136 \t Time_step: 199 \t Avg_reward: -84.90337 \t Cur_reward: -63.17452\n",
      "Task : 9 \t Episode: 137 \t Time_step: 199 \t Avg_reward: -84.02590 \t Cur_reward: -65.14448\n",
      "Task : 9 \t Episode: 138 \t Time_step: 199 \t Avg_reward: -83.12375 \t Cur_reward: -62.27447\n",
      "Task : 9 \t Episode: 139 \t Time_step: 199 \t Avg_reward: -82.23008 \t Cur_reward: -63.24419\n",
      "Task : 9 \t Episode: 140 \t Time_step: 199 \t Avg_reward: -81.31974 \t Cur_reward: -61.90588\n",
      "Task : 9 \t Episode: 141 \t Time_step: 199 \t Avg_reward: -80.42122 \t Cur_reward: -61.46855\n",
      "Task : 9 \t Episode: 142 \t Time_step: 199 \t Avg_reward: -79.53124 \t Cur_reward: -63.13070\n",
      "Task : 9 \t Episode: 143 \t Time_step: 199 \t Avg_reward: -78.63463 \t Cur_reward: -60.70422\n",
      "Task : 9 \t Episode: 144 \t Time_step: 199 \t Avg_reward: -77.74745 \t Cur_reward: -63.22925\n",
      "Task : 9 \t Episode: 145 \t Time_step: 199 \t Avg_reward: -76.85202 \t Cur_reward: -62.97968\n",
      "Task : 9 \t Episode: 146 \t Time_step: 199 \t Avg_reward: -75.96618 \t Cur_reward: -64.58109\n",
      "Task : 9 \t Episode: 147 \t Time_step: 199 \t Avg_reward: -75.08633 \t Cur_reward: -62.33892\n",
      "Task : 9 \t Episode: 148 \t Time_step: 199 \t Avg_reward: -74.33684 \t Cur_reward: -63.27048\n",
      "Task : 9 \t Episode: 149 \t Time_step: 199 \t Avg_reward: -73.59624 \t Cur_reward: -60.74401\n",
      "Task : 9 \t Episode: 150 \t Time_step: 199 \t Avg_reward: -72.91399 \t Cur_reward: -62.69403\n",
      "Task : 9 \t Episode: 151 \t Time_step: 199 \t Avg_reward: -72.25386 \t Cur_reward: -62.87662\n",
      "Task : 9 \t Episode: 152 \t Time_step: 199 \t Avg_reward: -71.59209 \t Cur_reward: -60.43027\n",
      "Task : 9 \t Episode: 153 \t Time_step: 199 \t Avg_reward: -70.96191 \t Cur_reward: -64.10738\n",
      "Task : 9 \t Episode: 154 \t Time_step: 199 \t Avg_reward: -70.31979 \t Cur_reward: -63.92852\n",
      "Task : 9 \t Episode: 155 \t Time_step: 199 \t Avg_reward: -69.66743 \t Cur_reward: -63.00610\n",
      "Task : 9 \t Episode: 156 \t Time_step: 199 \t Avg_reward: -69.09696 \t Cur_reward: -63.23423\n",
      "Task : 9 \t Episode: 157 \t Time_step: 199 \t Avg_reward: -68.57358 \t Cur_reward: -63.86217\n",
      "Task : 9 \t Episode: 158 \t Time_step: 199 \t Avg_reward: -68.03532 \t Cur_reward: -62.98898\n",
      "Task : 9 \t Episode: 159 \t Time_step: 199 \t Avg_reward: -67.57277 \t Cur_reward: -63.81180\n",
      "Task : 9 \t Episode: 160 \t Time_step: 199 \t Avg_reward: -67.11150 \t Cur_reward: -61.69247\n",
      "Task : 9 \t Episode: 161 \t Time_step: 199 \t Avg_reward: -66.71362 \t Cur_reward: -63.32183\n",
      "Task : 9 \t Episode: 162 \t Time_step: 199 \t Avg_reward: -66.32706 \t Cur_reward: -64.92715\n",
      "Task : 9 \t Episode: 163 \t Time_step: 199 \t Avg_reward: -66.04403 \t Cur_reward: -65.60309\n",
      "Task : 9 \t Episode: 164 \t Time_step: 199 \t Avg_reward: -65.72853 \t Cur_reward: -65.98402\n",
      "Task : 9 \t Episode: 165 \t Time_step: 199 \t Avg_reward: -65.39885 \t Cur_reward: -63.10306\n",
      "Task : 9 \t Episode: 166 \t Time_step: 199 \t Avg_reward: -65.08040 \t Cur_reward: -62.95226\n",
      "Task : 9 \t Episode: 167 \t Time_step: 199 \t Avg_reward: -64.83371 \t Cur_reward: -67.78094\n",
      "Task : 9 \t Episode: 168 \t Time_step: 199 \t Avg_reward: -64.70179 \t Cur_reward: -65.51800\n",
      "Task : 9 \t Episode: 169 \t Time_step: 199 \t Avg_reward: -64.63360 \t Cur_reward: -63.78458\n",
      "Task : 9 \t Episode: 170 \t Time_step: 199 \t Avg_reward: -64.58271 \t Cur_reward: -63.65920\n",
      "Task : 9 \t Episode: 171 \t Time_step: 199 \t Avg_reward: -64.46816 \t Cur_reward: -63.87920\n",
      "Task : 9 \t Episode: 172 \t Time_step: 199 \t Avg_reward: -64.41627 \t Cur_reward: -64.13680\n",
      "Task : 9 \t Episode: 173 \t Time_step: 199 \t Avg_reward: -64.38354 \t Cur_reward: -64.94960\n",
      "Task : 9 \t Episode: 174 \t Time_step: 199 \t Avg_reward: -64.33824 \t Cur_reward: -64.61638\n",
      "Task : 9 \t Episode: 175 \t Time_step: 199 \t Avg_reward: -64.31943 \t Cur_reward: -66.35279\n",
      "Task : 9 \t Episode: 176 \t Time_step: 199 \t Avg_reward: -64.24376 \t Cur_reward: -62.69312\n",
      "Task : 9 \t Episode: 177 \t Time_step: 199 \t Avg_reward: -64.16465 \t Cur_reward: -61.42423\n",
      "Task : 9 \t Episode: 178 \t Time_step: 199 \t Avg_reward: -64.11789 \t Cur_reward: -65.64218\n",
      "Task : 9 \t Episode: 179 \t Time_step: 199 \t Avg_reward: -64.05835 \t Cur_reward: -66.36097\n",
      "Task : 9 \t Episode: 180 \t Time_step: 199 \t Avg_reward: -64.06895 \t Cur_reward: -70.55404\n",
      "Task : 9 \t Episode: 181 \t Time_step: 199 \t Avg_reward: -64.01340 \t Cur_reward: -65.54731\n",
      "Task : 9 \t Episode: 182 \t Time_step: 199 \t Avg_reward: -63.98168 \t Cur_reward: -64.00817\n",
      "Task : 9 \t Episode: 183 \t Time_step: 199 \t Avg_reward: -63.89939 \t Cur_reward: -62.06838\n",
      "Task : 9 \t Episode: 184 \t Time_step: 199 \t Avg_reward: -63.86709 \t Cur_reward: -63.86876\n",
      "Task : 9 \t Episode: 185 \t Time_step: 199 \t Avg_reward: -63.81184 \t Cur_reward: -61.25439\n",
      "Task : 9 \t Episode: 186 \t Time_step: 199 \t Avg_reward: -63.72866 \t Cur_reward: -59.95752\n",
      "Task : 9 \t Episode: 187 \t Time_step: 199 \t Avg_reward: -63.65622 \t Cur_reward: -64.46527\n",
      "Task : 9 \t Episode: 188 \t Time_step: 199 \t Avg_reward: -63.59230 \t Cur_reward: -63.85909\n",
      "Task : 9 \t Episode: 189 \t Time_step: 199 \t Avg_reward: -63.47244 \t Cur_reward: -60.41372\n",
      "Task : 9 \t Episode: 190 \t Time_step: 199 \t Avg_reward: -63.42529 \t Cur_reward: -64.11375\n",
      "Task : 9 \t Episode: 191 \t Time_step: 199 \t Avg_reward: -63.36074 \t Cur_reward: -61.53537\n",
      "Task : 9 \t Episode: 192 \t Time_step: 199 \t Avg_reward: -63.30044 \t Cur_reward: -60.01147\n",
      "Task : 9 \t Episode: 193 \t Time_step: 199 \t Avg_reward: -63.26125 \t Cur_reward: -62.95757\n",
      "Task : 9 \t Episode: 194 \t Time_step: 199 \t Avg_reward: -63.24092 \t Cur_reward: -64.03522\n",
      "Task : 9 \t Episode: 195 \t Time_step: 199 \t Avg_reward: -63.32747 \t Cur_reward: -70.25831\n",
      "Task : 9 \t Episode: 196 \t Time_step: 199 \t Avg_reward: -63.34249 \t Cur_reward: -65.99119\n",
      "Task : 9 \t Episode: 197 \t Time_step: 199 \t Avg_reward: -63.46161 \t Cur_reward: -74.89585\n",
      "Task : 9 \t Episode: 198 \t Time_step: 199 \t Avg_reward: -63.46873 \t Cur_reward: -69.51353\n",
      "Task : 9 \t Episode: 199 \t Time_step: 199 \t Avg_reward: -63.54087 \t Cur_reward: -72.03919\n",
      "done\n",
      "Task : 9 \t Episode: 200 \t Time_step: 66 \t Avg_reward: -62.94151 \t Cur_reward: -3.65432\n",
      "Task : 9 \t Episode: 201 \t Time_step: 199 \t Avg_reward: -63.01762 \t Cur_reward: -70.62866\n",
      "Task : 9 \t Episode: 202 \t Time_step: 199 \t Avg_reward: -63.09853 \t Cur_reward: -70.12374\n",
      "Task : 9 \t Episode: 203 \t Time_step: 199 \t Avg_reward: -63.15577 \t Cur_reward: -69.31792\n",
      "Task : 9 \t Episode: 204 \t Time_step: 199 \t Avg_reward: -63.22154 \t Cur_reward: -68.80881\n",
      "Task : 9 \t Episode: 205 \t Time_step: 199 \t Avg_reward: -63.32382 \t Cur_reward: -76.11893\n",
      "Task : 9 \t Episode: 206 \t Time_step: 199 \t Avg_reward: -63.47421 \t Cur_reward: -77.51532\n",
      "Task : 9 \t Episode: 207 \t Time_step: 199 \t Avg_reward: -63.61410 \t Cur_reward: -76.12917\n",
      "Task : 9 \t Episode: 208 \t Time_step: 199 \t Avg_reward: -63.76118 \t Cur_reward: -77.43084\n",
      "Task : 9 \t Episode: 209 \t Time_step: 199 \t Avg_reward: -63.92310 \t Cur_reward: -79.60306\n",
      "Task : 9 \t Episode: 210 \t Time_step: 199 \t Avg_reward: -64.07937 \t Cur_reward: -78.40009\n",
      "Task : 9 \t Episode: 211 \t Time_step: 199 \t Avg_reward: -64.20878 \t Cur_reward: -78.97791\n",
      "Task : 9 \t Episode: 212 \t Time_step: 199 \t Avg_reward: -64.39102 \t Cur_reward: -78.75433\n",
      "Task : 9 \t Episode: 213 \t Time_step: 199 \t Avg_reward: -64.58203 \t Cur_reward: -79.53396\n",
      "Task : 9 \t Episode: 214 \t Time_step: 199 \t Avg_reward: -64.75296 \t Cur_reward: -78.86550\n",
      "Task : 9 \t Episode: 215 \t Time_step: 199 \t Avg_reward: -64.95932 \t Cur_reward: -81.81707\n",
      "Task : 9 \t Episode: 216 \t Time_step: 199 \t Avg_reward: -65.13760 \t Cur_reward: -81.18074\n",
      "Task : 9 \t Episode: 217 \t Time_step: 199 \t Avg_reward: -65.35539 \t Cur_reward: -84.26164\n",
      "Task : 9 \t Episode: 218 \t Time_step: 199 \t Avg_reward: -65.54510 \t Cur_reward: -80.28730\n",
      "Task : 9 \t Episode: 219 \t Time_step: 199 \t Avg_reward: -65.73180 \t Cur_reward: -79.38112\n",
      "Task : 9 \t Episode: 220 \t Time_step: 199 \t Avg_reward: -65.89656 \t Cur_reward: -78.72462\n",
      "Task : 9 \t Episode: 221 \t Time_step: 199 \t Avg_reward: -66.06289 \t Cur_reward: -79.89902\n",
      "Task : 9 \t Episode: 222 \t Time_step: 199 \t Avg_reward: -66.19530 \t Cur_reward: -77.00798\n",
      "Task : 9 \t Episode: 223 \t Time_step: 199 \t Avg_reward: -66.34997 \t Cur_reward: -77.25150\n",
      "Task : 9 \t Episode: 224 \t Time_step: 199 \t Avg_reward: -66.47672 \t Cur_reward: -75.64172\n",
      "Task : 9 \t Episode: 225 \t Time_step: 199 \t Avg_reward: -66.62267 \t Cur_reward: -76.77694\n",
      "Task : 9 \t Episode: 226 \t Time_step: 199 \t Avg_reward: -66.79094 \t Cur_reward: -79.77296\n",
      "Task : 9 \t Episode: 227 \t Time_step: 199 \t Avg_reward: -66.93149 \t Cur_reward: -75.01999\n",
      "Task : 9 \t Episode: 228 \t Time_step: 199 \t Avg_reward: -67.06172 \t Cur_reward: -75.90562\n",
      "Task : 9 \t Episode: 229 \t Time_step: 199 \t Avg_reward: -67.20762 \t Cur_reward: -77.76427\n",
      "Task : 9 \t Episode: 230 \t Time_step: 199 \t Avg_reward: -67.28477 \t Cur_reward: -71.25366\n",
      "done\n",
      "Task : 9 \t Episode: 231 \t Time_step: 33 \t Avg_reward: -66.71539 \t Cur_reward: -3.11320\n",
      "Task : 9 \t Episode: 232 \t Time_step: 199 \t Avg_reward: -66.77794 \t Cur_reward: -68.56894\n",
      "Task : 9 \t Episode: 233 \t Time_step: 199 \t Avg_reward: -66.80692 \t Cur_reward: -66.30534\n",
      "done\n",
      "Task : 9 \t Episode: 234 \t Time_step: 31 \t Avg_reward: -66.18350 \t Cur_reward: -2.09260\n",
      "Task : 9 \t Episode: 235 \t Time_step: 199 \t Avg_reward: -66.24940 \t Cur_reward: -70.19030\n",
      "done\n",
      "Task : 9 \t Episode: 236 \t Time_step: 39 \t Avg_reward: -65.64709 \t Cur_reward: -2.94440\n",
      "Task : 9 \t Episode: 237 \t Time_step: 199 \t Avg_reward: -65.68035 \t Cur_reward: -68.47014\n",
      "Task : 9 \t Episode: 238 \t Time_step: 199 \t Avg_reward: -65.73671 \t Cur_reward: -67.90988\n",
      "done\n",
      "Task : 9 \t Episode: 239 \t Time_step: 30 \t Avg_reward: -65.12675 \t Cur_reward: -2.24854\n",
      "Task : 9 \t Episode: 240 \t Time_step: 199 \t Avg_reward: -65.15805 \t Cur_reward: -65.03577\n",
      "Task : 9 \t Episode: 241 \t Time_step: 199 \t Avg_reward: -65.23286 \t Cur_reward: -68.95005\n",
      "Task : 9 \t Episode: 242 \t Time_step: 199 \t Avg_reward: -65.24631 \t Cur_reward: -64.47518\n",
      "Task : 9 \t Episode: 243 \t Time_step: 199 \t Avg_reward: -65.33680 \t Cur_reward: -69.75364\n",
      "Task : 9 \t Episode: 244 \t Time_step: 199 \t Avg_reward: -65.31162 \t Cur_reward: -60.71064\n",
      "done\n",
      "Task : 9 \t Episode: 245 \t Time_step: 34 \t Avg_reward: -64.71077 \t Cur_reward: -2.89542\n",
      "Task : 9 \t Episode: 246 \t Time_step: 199 \t Avg_reward: -64.69909 \t Cur_reward: -63.41266\n",
      "Task : 9 \t Episode: 247 \t Time_step: 199 \t Avg_reward: -64.68887 \t Cur_reward: -61.31732\n",
      "Task : 9 \t Episode: 248 \t Time_step: 199 \t Avg_reward: -64.72942 \t Cur_reward: -67.32474\n",
      "Task : 9 \t Episode: 249 \t Time_step: 199 \t Avg_reward: -64.78780 \t Cur_reward: -66.58251\n",
      "Task : 9 \t Episode: 250 \t Time_step: 199 \t Avg_reward: -64.77238 \t Cur_reward: -61.15202\n",
      "Task : 9 \t Episode: 251 \t Time_step: 199 \t Avg_reward: -64.83283 \t Cur_reward: -68.92202\n",
      "Task : 9 \t Episode: 252 \t Time_step: 199 \t Avg_reward: -64.89625 \t Cur_reward: -66.77164\n",
      "Task : 9 \t Episode: 253 \t Time_step: 199 \t Avg_reward: -64.92368 \t Cur_reward: -66.85025\n",
      "done\n",
      "Task : 9 \t Episode: 254 \t Time_step: 41 \t Avg_reward: -64.31493 \t Cur_reward: -3.05344\n",
      "done\n",
      "Task : 9 \t Episode: 255 \t Time_step: 38 \t Avg_reward: -63.71419 \t Cur_reward: -2.93255\n",
      "Task : 9 \t Episode: 256 \t Time_step: 199 \t Avg_reward: -63.79221 \t Cur_reward: -71.03619\n",
      "Task : 9 \t Episode: 257 \t Time_step: 199 \t Avg_reward: -63.86340 \t Cur_reward: -70.98092\n",
      "Task : 9 \t Episode: 258 \t Time_step: 199 \t Avg_reward: -63.88741 \t Cur_reward: -65.39068\n",
      "Task : 9 \t Episode: 259 \t Time_step: 199 \t Avg_reward: -63.94490 \t Cur_reward: -69.56016\n",
      "Task : 9 \t Episode: 260 \t Time_step: 199 \t Avg_reward: -64.02925 \t Cur_reward: -70.12789\n",
      "done\n",
      "Task : 9 \t Episode: 261 \t Time_step: 64 \t Avg_reward: -63.42664 \t Cur_reward: -3.06092\n",
      "done\n",
      "Task : 9 \t Episode: 262 \t Time_step: 48 \t Avg_reward: -62.80128 \t Cur_reward: -2.39058\n",
      "Task : 9 \t Episode: 263 \t Time_step: 199 \t Avg_reward: -62.76570 \t Cur_reward: -62.04545\n",
      "done\n",
      "Task : 9 \t Episode: 264 \t Time_step: 65 \t Avg_reward: -62.13083 \t Cur_reward: -2.49700\n",
      "done\n",
      "Task : 9 \t Episode: 265 \t Time_step: 43 \t Avg_reward: -61.51776 \t Cur_reward: -1.79619\n",
      "done\n",
      "Task : 9 \t Episode: 266 \t Time_step: 44 \t Avg_reward: -60.90947 \t Cur_reward: -2.12291\n",
      "done\n",
      "Task : 9 \t Episode: 267 \t Time_step: 39 \t Avg_reward: -60.25931 \t Cur_reward: -2.76544\n",
      "done\n",
      "Task : 9 \t Episode: 268 \t Time_step: 43 \t Avg_reward: -59.63407 \t Cur_reward: -2.99357\n",
      "done\n",
      "Task : 9 \t Episode: 269 \t Time_step: 43 \t Avg_reward: -59.02244 \t Cur_reward: -2.62115\n",
      "Task : 9 \t Episode: 270 \t Time_step: 199 \t Avg_reward: -58.97171 \t Cur_reward: -58.58688\n",
      "Task : 9 \t Episode: 271 \t Time_step: 199 \t Avg_reward: -58.97779 \t Cur_reward: -64.48704\n",
      "done\n",
      "Task : 9 \t Episode: 272 \t Time_step: 68 \t Avg_reward: -58.35722 \t Cur_reward: -2.08005\n",
      "done\n",
      "Task : 9 \t Episode: 273 \t Time_step: 31 \t Avg_reward: -57.72262 \t Cur_reward: -1.48912\n",
      "Task : 9 \t Episode: 274 \t Time_step: 199 \t Avg_reward: -57.67709 \t Cur_reward: -60.06304\n",
      "done\n",
      "Task : 9 \t Episode: 275 \t Time_step: 46 \t Avg_reward: -57.02673 \t Cur_reward: -1.31725\n",
      "done\n",
      "Task : 9 \t Episode: 276 \t Time_step: 50 \t Avg_reward: -56.42518 \t Cur_reward: -2.53785\n",
      "done\n",
      "Task : 9 \t Episode: 277 \t Time_step: 65 \t Avg_reward: -55.83827 \t Cur_reward: -2.73400\n",
      "done\n",
      "Task : 9 \t Episode: 278 \t Time_step: 43 \t Avg_reward: -55.20935 \t Cur_reward: -2.74945\n",
      "Task : 9 \t Episode: 279 \t Time_step: 199 \t Avg_reward: -55.16437 \t Cur_reward: -61.86334\n",
      "done\n",
      "Task : 9 \t Episode: 280 \t Time_step: 41 \t Avg_reward: -54.48565 \t Cur_reward: -2.68191\n",
      "done\n",
      "Task : 9 \t Episode: 281 \t Time_step: 64 \t Avg_reward: -53.85929 \t Cur_reward: -2.91139\n",
      "done\n",
      "Task : 9 \t Episode: 282 \t Time_step: 43 \t Avg_reward: -53.24018 \t Cur_reward: -2.09730\n",
      "Task : 9 \t Episode: 283 \t Time_step: 199 \t Avg_reward: -53.14235 \t Cur_reward: -52.28503\n",
      "done\n",
      "Task : 9 \t Episode: 284 \t Time_step: 67 \t Avg_reward: -52.53052 \t Cur_reward: -2.68567\n",
      "done\n",
      "Task : 9 \t Episode: 285 \t Time_step: 55 \t Avg_reward: -51.94343 \t Cur_reward: -2.54545\n",
      "done\n",
      "Task : 9 \t Episode: 286 \t Time_step: 43 \t Avg_reward: -51.36480 \t Cur_reward: -2.09460\n",
      "done\n",
      "Task : 9 \t Episode: 287 \t Time_step: 66 \t Avg_reward: -50.74755 \t Cur_reward: -2.74001\n",
      "done\n",
      "Task : 9 \t Episode: 288 \t Time_step: 55 \t Avg_reward: -50.12746 \t Cur_reward: -1.85063\n",
      "done\n",
      "Task : 9 \t Episode: 289 \t Time_step: 54 \t Avg_reward: -49.55331 \t Cur_reward: -2.99835\n",
      "done\n",
      "Task : 9 \t Episode: 290 \t Time_step: 56 \t Avg_reward: -48.93543 \t Cur_reward: -2.32588\n",
      "done\n",
      "Task : 9 \t Episode: 291 \t Time_step: 64 \t Avg_reward: -48.34517 \t Cur_reward: -2.50915\n",
      "done\n",
      "Task : 9 \t Episode: 292 \t Time_step: 65 \t Avg_reward: -47.77309 \t Cur_reward: -2.80372\n",
      "done\n",
      "Task : 9 \t Episode: 293 \t Time_step: 49 \t Avg_reward: -47.16624 \t Cur_reward: -2.27305\n",
      "done\n",
      "Task : 9 \t Episode: 294 \t Time_step: 64 \t Avg_reward: -46.55276 \t Cur_reward: -2.68714\n",
      "Task : 9 \t Episode: 295 \t Time_step: 199 \t Avg_reward: -46.39270 \t Cur_reward: -54.25210\n",
      "done\n",
      "Task : 9 \t Episode: 296 \t Time_step: 64 \t Avg_reward: -45.76147 \t Cur_reward: -2.86834\n",
      "done\n",
      "Task : 9 \t Episode: 297 \t Time_step: 47 \t Avg_reward: -45.03833 \t Cur_reward: -2.58180\n",
      "done\n",
      "Task : 9 \t Episode: 298 \t Time_step: 65 \t Avg_reward: -44.37151 \t Cur_reward: -2.83142\n",
      "Task : 9 \t Episode: 299 \t Time_step: 199 \t Avg_reward: -44.21263 \t Cur_reward: -56.15096\n",
      "done\n",
      "Task : 9 \t Episode: 300 \t Time_step: 55 \t Avg_reward: -44.19363 \t Cur_reward: -1.75405\n",
      "done\n",
      "Task : 9 \t Episode: 301 \t Time_step: 53 \t Avg_reward: -43.51036 \t Cur_reward: -2.30225\n",
      "Task : 9 \t Episode: 302 \t Time_step: 199 \t Avg_reward: -43.47522 \t Cur_reward: -66.60943\n",
      "Task : 9 \t Episode: 303 \t Time_step: 199 \t Avg_reward: -43.39529 \t Cur_reward: -61.32543\n",
      "done\n",
      "Task : 9 \t Episode: 304 \t Time_step: 58 \t Avg_reward: -42.73027 \t Cur_reward: -2.30676\n",
      "done\n",
      "Task : 9 \t Episode: 305 \t Time_step: 55 \t Avg_reward: -41.98936 \t Cur_reward: -2.02802\n",
      "Task : 9 \t Episode: 306 \t Time_step: 199 \t Avg_reward: -41.81492 \t Cur_reward: -60.07093\n",
      "Task : 9 \t Episode: 307 \t Time_step: 199 \t Avg_reward: -41.67106 \t Cur_reward: -61.74299\n",
      "Task : 9 \t Episode: 308 \t Time_step: 199 \t Avg_reward: -41.47733 \t Cur_reward: -58.05748\n",
      "done\n",
      "Task : 9 \t Episode: 309 \t Time_step: 68 \t Avg_reward: -40.70036 \t Cur_reward: -1.90699\n",
      "done\n",
      "Task : 9 \t Episode: 310 \t Time_step: 62 \t Avg_reward: -39.93813 \t Cur_reward: -2.17683\n",
      "Task : 9 \t Episode: 311 \t Time_step: 199 \t Avg_reward: -39.69317 \t Cur_reward: -54.48177\n",
      "done\n",
      "Task : 9 \t Episode: 312 \t Time_step: 75 \t Avg_reward: -38.93903 \t Cur_reward: -3.34007\n",
      "Task : 9 \t Episode: 313 \t Time_step: 199 \t Avg_reward: -38.64957 \t Cur_reward: -50.58865\n",
      "Task : 9 \t Episode: 314 \t Time_step: 199 \t Avg_reward: -38.33150 \t Cur_reward: -47.05848\n",
      "done\n",
      "Task : 9 \t Episode: 315 \t Time_step: 52 \t Avg_reward: -37.54620 \t Cur_reward: -3.28683\n",
      "done\n",
      "Task : 9 \t Episode: 316 \t Time_step: 81 \t Avg_reward: -36.76307 \t Cur_reward: -2.86783\n",
      "Task : 9 \t Episode: 317 \t Time_step: 199 \t Avg_reward: -36.38146 \t Cur_reward: -46.10058\n",
      "Task : 9 \t Episode: 318 \t Time_step: 199 \t Avg_reward: -36.03018 \t Cur_reward: -45.15946\n",
      "Task : 9 \t Episode: 319 \t Time_step: 199 \t Avg_reward: -35.73692 \t Cur_reward: -50.05503\n",
      "Task : 9 \t Episode: 320 \t Time_step: 199 \t Avg_reward: -35.34234 \t Cur_reward: -39.26606\n",
      "Task : 9 \t Episode: 321 \t Time_step: 199 \t Avg_reward: -34.98797 \t Cur_reward: -44.46264\n",
      "done\n",
      "Task : 9 \t Episode: 322 \t Time_step: 67 \t Avg_reward: -34.24013 \t Cur_reward: -2.22380\n",
      "Task : 9 \t Episode: 323 \t Time_step: 199 \t Avg_reward: -33.85391 \t Cur_reward: -38.62880\n",
      "Task : 9 \t Episode: 324 \t Time_step: 199 \t Avg_reward: -33.47855 \t Cur_reward: -38.10575\n",
      "Task : 9 \t Episode: 325 \t Time_step: 199 \t Avg_reward: -33.13561 \t Cur_reward: -42.48317\n",
      "Task : 9 \t Episode: 326 \t Time_step: 199 \t Avg_reward: -32.66190 \t Cur_reward: -32.40213\n",
      "Task : 9 \t Episode: 327 \t Time_step: 199 \t Avg_reward: -32.30045 \t Cur_reward: -38.87460\n",
      "Task : 9 \t Episode: 328 \t Time_step: 199 \t Avg_reward: -31.90038 \t Cur_reward: -35.89905\n",
      "Task : 9 \t Episode: 329 \t Time_step: 199 \t Avg_reward: -31.51821 \t Cur_reward: -39.54717\n",
      "Task : 9 \t Episode: 330 \t Time_step: 199 \t Avg_reward: -31.11499 \t Cur_reward: -30.93197\n",
      "Task : 9 \t Episode: 331 \t Time_step: 199 \t Avg_reward: -31.39065 \t Cur_reward: -30.67950\n",
      "Task : 9 \t Episode: 332 \t Time_step: 199 \t Avg_reward: -31.04614 \t Cur_reward: -34.11730\n",
      "Task : 9 \t Episode: 333 \t Time_step: 199 \t Avg_reward: -30.74165 \t Cur_reward: -35.85612\n",
      "Task : 9 \t Episode: 334 \t Time_step: 199 \t Avg_reward: -31.06987 \t Cur_reward: -34.91451\n",
      "Task : 9 \t Episode: 335 \t Time_step: 199 \t Avg_reward: -30.73587 \t Cur_reward: -36.79038\n",
      "Task : 9 \t Episode: 336 \t Time_step: 199 \t Avg_reward: -31.11578 \t Cur_reward: -40.93618\n",
      "Task : 9 \t Episode: 337 \t Time_step: 199 \t Avg_reward: -30.73035 \t Cur_reward: -29.92625\n",
      "Task : 9 \t Episode: 338 \t Time_step: 199 \t Avg_reward: -30.38978 \t Cur_reward: -33.85354\n",
      "Task : 9 \t Episode: 339 \t Time_step: 199 \t Avg_reward: -30.59993 \t Cur_reward: -23.26385\n",
      "Task : 9 \t Episode: 340 \t Time_step: 199 \t Avg_reward: -30.23588 \t Cur_reward: -28.63004\n",
      "Task : 9 \t Episode: 341 \t Time_step: 199 \t Avg_reward: -29.86078 \t Cur_reward: -31.44021\n",
      "Task : 9 \t Episode: 342 \t Time_step: 199 \t Avg_reward: -29.45640 \t Cur_reward: -24.03740\n",
      "Task : 9 \t Episode: 343 \t Time_step: 199 \t Avg_reward: -29.05211 \t Cur_reward: -29.32453\n",
      "Task : 9 \t Episode: 344 \t Time_step: 199 \t Avg_reward: -28.75830 \t Cur_reward: -31.32969\n",
      "Task : 9 \t Episode: 345 \t Time_step: 199 \t Avg_reward: -29.05529 \t Cur_reward: -32.59404\n",
      "Task : 9 \t Episode: 346 \t Time_step: 199 \t Avg_reward: -28.76990 \t Cur_reward: -34.87411\n",
      "Task : 9 \t Episode: 347 \t Time_step: 199 \t Avg_reward: -28.42175 \t Cur_reward: -26.50218\n",
      "Task : 9 \t Episode: 348 \t Time_step: 199 \t Avg_reward: -27.99490 \t Cur_reward: -24.63990\n",
      "Task : 9 \t Episode: 349 \t Time_step: 199 \t Avg_reward: -27.63248 \t Cur_reward: -30.34053\n",
      "Task : 9 \t Episode: 350 \t Time_step: 199 \t Avg_reward: -27.27634 \t Cur_reward: -25.53764\n",
      "Task : 9 \t Episode: 351 \t Time_step: 199 \t Avg_reward: -26.85253 \t Cur_reward: -26.54128\n",
      "Task : 9 \t Episode: 352 \t Time_step: 199 \t Avg_reward: -26.44907 \t Cur_reward: -26.42555\n",
      "Task : 9 \t Episode: 353 \t Time_step: 199 \t Avg_reward: -26.01901 \t Cur_reward: -23.84444\n",
      "Task : 9 \t Episode: 354 \t Time_step: 199 \t Avg_reward: -26.23545 \t Cur_reward: -24.69698\n",
      "Task : 9 \t Episode: 355 \t Time_step: 199 \t Avg_reward: -26.41133 \t Cur_reward: -20.52127\n",
      "Task : 9 \t Episode: 356 \t Time_step: 199 \t Avg_reward: -25.97368 \t Cur_reward: -27.27054\n",
      "done\n",
      "Task : 9 \t Episode: 357 \t Time_step: 126 \t Avg_reward: -25.36656 \t Cur_reward: -10.26914\n",
      "Task : 9 \t Episode: 358 \t Time_step: 199 \t Avg_reward: -24.94917 \t Cur_reward: -23.65180\n",
      "done\n",
      "Task : 9 \t Episode: 359 \t Time_step: 119 \t Avg_reward: -24.33129 \t Cur_reward: -7.77157\n",
      "done\n",
      "Task : 9 \t Episode: 360 \t Time_step: 121 \t Avg_reward: -23.75273 \t Cur_reward: -12.27267\n",
      "Task : 9 \t Episode: 361 \t Time_step: 199 \t Avg_reward: -23.97501 \t Cur_reward: -25.28902\n",
      "done\n",
      "Task : 9 \t Episode: 362 \t Time_step: 131 \t Avg_reward: -24.06068 \t Cur_reward: -10.95689\n",
      "done\n",
      "Task : 9 \t Episode: 363 \t Time_step: 124 \t Avg_reward: -23.53242 \t Cur_reward: -9.21943\n",
      "done\n",
      "Task : 9 \t Episode: 364 \t Time_step: 128 \t Avg_reward: -23.59501 \t Cur_reward: -8.75621\n",
      "done\n",
      "Task : 9 \t Episode: 365 \t Time_step: 127 \t Avg_reward: -23.66644 \t Cur_reward: -8.93952\n",
      "Task : 9 \t Episode: 366 \t Time_step: 199 \t Avg_reward: -23.83706 \t Cur_reward: -19.18504\n",
      "Task : 9 \t Episode: 367 \t Time_step: 199 \t Avg_reward: -24.07721 \t Cur_reward: -26.78059\n",
      "Task : 9 \t Episode: 368 \t Time_step: 199 \t Avg_reward: -24.25717 \t Cur_reward: -20.98951\n",
      "done\n",
      "Task : 9 \t Episode: 369 \t Time_step: 127 \t Avg_reward: -24.34181 \t Cur_reward: -11.08501\n",
      "Task : 9 \t Episode: 370 \t Time_step: 199 \t Avg_reward: -23.96929 \t Cur_reward: -21.33421\n",
      "Task : 9 \t Episode: 371 \t Time_step: 199 \t Avg_reward: -23.48828 \t Cur_reward: -16.38684\n",
      "done\n",
      "Task : 9 \t Episode: 372 \t Time_step: 132 \t Avg_reward: -23.56469 \t Cur_reward: -9.72036\n",
      "Task : 9 \t Episode: 373 \t Time_step: 199 \t Avg_reward: -23.74285 \t Cur_reward: -19.30504\n",
      "Task : 9 \t Episode: 374 \t Time_step: 199 \t Avg_reward: -23.34833 \t Cur_reward: -20.61153\n",
      "Task : 9 \t Episode: 375 \t Time_step: 199 \t Avg_reward: -23.61459 \t Cur_reward: -27.94357\n",
      "Task : 9 \t Episode: 376 \t Time_step: 199 \t Avg_reward: -23.92145 \t Cur_reward: -33.22308\n",
      "Task : 9 \t Episode: 377 \t Time_step: 199 \t Avg_reward: -24.13041 \t Cur_reward: -23.63004\n",
      "Task : 9 \t Episode: 378 \t Time_step: 199 \t Avg_reward: -24.28639 \t Cur_reward: -18.34782\n",
      "Task : 9 \t Episode: 379 \t Time_step: 199 \t Avg_reward: -23.89525 \t Cur_reward: -22.74921\n",
      "done\n",
      "Task : 9 \t Episode: 380 \t Time_step: 126 \t Avg_reward: -23.95375 \t Cur_reward: -8.53203\n",
      "Task : 9 \t Episode: 381 \t Time_step: 199 \t Avg_reward: -24.07292 \t Cur_reward: -14.82865\n",
      "Task : 9 \t Episode: 382 \t Time_step: 199 \t Avg_reward: -24.22318 \t Cur_reward: -17.12254\n",
      "Task : 9 \t Episode: 383 \t Time_step: 199 \t Avg_reward: -23.88646 \t Cur_reward: -18.61373\n",
      "Task : 9 \t Episode: 384 \t Time_step: 199 \t Avg_reward: -24.10713 \t Cur_reward: -24.75245\n",
      "Task : 9 \t Episode: 385 \t Time_step: 199 \t Avg_reward: -24.29097 \t Cur_reward: -20.92983\n",
      "Task : 9 \t Episode: 386 \t Time_step: 199 \t Avg_reward: -24.44179 \t Cur_reward: -17.17663\n",
      "Task : 9 \t Episode: 387 \t Time_step: 199 \t Avg_reward: -24.65783 \t Cur_reward: -24.34358\n",
      "Task : 9 \t Episode: 388 \t Time_step: 199 \t Avg_reward: -24.84759 \t Cur_reward: -20.82694\n",
      "Task : 9 \t Episode: 389 \t Time_step: 199 \t Avg_reward: -25.04118 \t Cur_reward: -22.35694\n",
      "Task : 9 \t Episode: 390 \t Time_step: 199 \t Avg_reward: -25.23089 \t Cur_reward: -21.29726\n",
      "Task : 9 \t Episode: 391 \t Time_step: 199 \t Avg_reward: -25.46503 \t Cur_reward: -25.92248\n",
      "Task : 9 \t Episode: 392 \t Time_step: 199 \t Avg_reward: -25.72959 \t Cur_reward: -29.26005\n",
      "Task : 9 \t Episode: 393 \t Time_step: 199 \t Avg_reward: -25.97866 \t Cur_reward: -27.18038\n",
      "Task : 9 \t Episode: 394 \t Time_step: 199 \t Avg_reward: -26.19750 \t Cur_reward: -24.57092\n",
      "Task : 9 \t Episode: 395 \t Time_step: 199 \t Avg_reward: -25.95474 \t Cur_reward: -29.97558\n",
      "Task : 9 \t Episode: 396 \t Time_step: 199 \t Avg_reward: -26.20842 \t Cur_reward: -28.23660\n",
      "Task : 9 \t Episode: 397 \t Time_step: 199 \t Avg_reward: -26.44878 \t Cur_reward: -26.61824\n",
      "Task : 9 \t Episode: 398 \t Time_step: 199 \t Avg_reward: -26.67832 \t Cur_reward: -25.78502\n",
      "Task : 9 \t Episode: 399 \t Time_step: 199 \t Avg_reward: -26.39735 \t Cur_reward: -28.05454\n",
      "Task : 9 \t Episode: 400 \t Time_step: 199 \t Avg_reward: -26.66424 \t Cur_reward: -28.44246\n",
      "Task : 9 \t Episode: 401 \t Time_step: 199 \t Avg_reward: -26.90465 \t Cur_reward: -26.34310\n",
      "Task : 9 \t Episode: 402 \t Time_step: 199 \t Avg_reward: -26.49804 \t Cur_reward: -25.94915\n",
      "Task : 9 \t Episode: 403 \t Time_step: 199 \t Avg_reward: -26.13270 \t Cur_reward: -24.79080\n",
      "Task : 9 \t Episode: 404 \t Time_step: 199 \t Avg_reward: -26.31154 \t Cur_reward: -20.19101\n",
      "Task : 9 \t Episode: 405 \t Time_step: 199 \t Avg_reward: -26.60474 \t Cur_reward: -31.34815\n",
      "Task : 9 \t Episode: 406 \t Time_step: 199 \t Avg_reward: -26.27277 \t Cur_reward: -26.87343\n",
      "Task : 9 \t Episode: 407 \t Time_step: 199 \t Avg_reward: -25.93817 \t Cur_reward: -28.28354\n",
      "Task : 9 \t Episode: 408 \t Time_step: 199 \t Avg_reward: -25.65461 \t Cur_reward: -29.70166\n",
      "Task : 9 \t Episode: 409 \t Time_step: 199 \t Avg_reward: -25.94399 \t Cur_reward: -30.84471\n",
      "Task : 9 \t Episode: 410 \t Time_step: 199 \t Avg_reward: -26.20903 \t Cur_reward: -28.68031\n",
      "Task : 9 \t Episode: 411 \t Time_step: 199 \t Avg_reward: -26.00303 \t Cur_reward: -33.88209\n",
      "Task : 9 \t Episode: 412 \t Time_step: 199 \t Avg_reward: -26.29075 \t Cur_reward: -32.11234\n",
      "Task : 9 \t Episode: 413 \t Time_step: 199 \t Avg_reward: -26.05471 \t Cur_reward: -26.98411\n",
      "Task : 9 \t Episode: 414 \t Time_step: 199 \t Avg_reward: -25.87281 \t Cur_reward: -28.86900\n",
      "Task : 9 \t Episode: 415 \t Time_step: 199 \t Avg_reward: -26.05624 \t Cur_reward: -21.62951\n",
      "Task : 9 \t Episode: 416 \t Time_step: 199 \t Avg_reward: -26.24109 \t Cur_reward: -21.35339\n",
      "Task : 9 \t Episode: 417 \t Time_step: 199 \t Avg_reward: -26.00595 \t Cur_reward: -22.58590\n",
      "Task : 9 \t Episode: 418 \t Time_step: 199 \t Avg_reward: -25.76942 \t Cur_reward: -21.50680\n",
      "Task : 9 \t Episode: 419 \t Time_step: 199 \t Avg_reward: -25.47781 \t Cur_reward: -20.89351\n",
      "Task : 9 \t Episode: 420 \t Time_step: 199 \t Avg_reward: -25.29707 \t Cur_reward: -21.19297\n",
      "Task : 9 \t Episode: 421 \t Time_step: 199 \t Avg_reward: -25.09107 \t Cur_reward: -23.86266\n",
      "Task : 9 \t Episode: 422 \t Time_step: 199 \t Avg_reward: -25.24990 \t Cur_reward: -18.10675\n",
      "Task : 9 \t Episode: 423 \t Time_step: 199 \t Avg_reward: -25.07212 \t Cur_reward: -20.85086\n",
      "Task : 9 \t Episode: 424 \t Time_step: 199 \t Avg_reward: -24.88886 \t Cur_reward: -19.77960\n",
      "Task : 9 \t Episode: 425 \t Time_step: 199 \t Avg_reward: -24.67527 \t Cur_reward: -21.12336\n",
      "Task : 9 \t Episode: 426 \t Time_step: 199 \t Avg_reward: -24.53511 \t Cur_reward: -18.38703\n",
      "Task : 9 \t Episode: 427 \t Time_step: 199 \t Avg_reward: -24.34989 \t Cur_reward: -20.35235\n",
      "Task : 9 \t Episode: 428 \t Time_step: 199 \t Avg_reward: -24.11684 \t Cur_reward: -12.59351\n",
      "Task : 9 \t Episode: 429 \t Time_step: 199 \t Avg_reward: -23.91386 \t Cur_reward: -19.24991\n",
      "Task : 9 \t Episode: 430 \t Time_step: 199 \t Avg_reward: -23.78890 \t Cur_reward: -18.43525\n",
      "Task : 9 \t Episode: 431 \t Time_step: 199 \t Avg_reward: -23.66025 \t Cur_reward: -17.81472\n",
      "Task : 9 \t Episode: 432 \t Time_step: 199 \t Avg_reward: -23.52821 \t Cur_reward: -20.91381\n",
      "Task : 9 \t Episode: 433 \t Time_step: 199 \t Avg_reward: -23.33155 \t Cur_reward: -16.18926\n",
      "Task : 9 \t Episode: 434 \t Time_step: 199 \t Avg_reward: -23.16921 \t Cur_reward: -18.68143\n",
      "Task : 9 \t Episode: 435 \t Time_step: 199 \t Avg_reward: -22.99191 \t Cur_reward: -19.05994\n",
      "Task : 9 \t Episode: 436 \t Time_step: 199 \t Avg_reward: -22.81464 \t Cur_reward: -23.20958\n",
      "Task : 9 \t Episode: 437 \t Time_step: 199 \t Avg_reward: -22.72810 \t Cur_reward: -21.27226\n",
      "Task : 9 \t Episode: 438 \t Time_step: 199 \t Avg_reward: -22.64533 \t Cur_reward: -25.57567\n",
      "Task : 9 \t Episode: 439 \t Time_step: 199 \t Avg_reward: -22.59211 \t Cur_reward: -17.94236\n",
      "Task : 9 \t Episode: 440 \t Time_step: 199 \t Avg_reward: -22.49952 \t Cur_reward: -19.37115\n",
      "Task : 9 \t Episode: 441 \t Time_step: 199 \t Avg_reward: -22.35363 \t Cur_reward: -16.85148\n",
      "Task : 9 \t Episode: 442 \t Time_step: 199 \t Avg_reward: -22.29191 \t Cur_reward: -17.86458\n",
      "Task : 9 \t Episode: 443 \t Time_step: 199 \t Avg_reward: -22.21724 \t Cur_reward: -21.85761\n",
      "Task : 9 \t Episode: 444 \t Time_step: 199 \t Avg_reward: -22.07889 \t Cur_reward: -17.49476\n",
      "Task : 9 \t Episode: 445 \t Time_step: 199 \t Avg_reward: -21.92876 \t Cur_reward: -17.58158\n",
      "Task : 9 \t Episode: 446 \t Time_step: 199 \t Avg_reward: -21.80151 \t Cur_reward: -22.14880\n",
      "Task : 9 \t Episode: 447 \t Time_step: 199 \t Avg_reward: -21.66207 \t Cur_reward: -12.55804\n",
      "Task : 9 \t Episode: 448 \t Time_step: 199 \t Avg_reward: -21.57529 \t Cur_reward: -15.96206\n",
      "Task : 9 \t Episode: 449 \t Time_step: 199 \t Avg_reward: -21.42936 \t Cur_reward: -15.74786\n",
      "Task : 9 \t Episode: 450 \t Time_step: 199 \t Avg_reward: -21.35778 \t Cur_reward: -18.37921\n",
      "Task : 9 \t Episode: 451 \t Time_step: 199 \t Avg_reward: -21.26655 \t Cur_reward: -17.41862\n",
      "Task : 9 \t Episode: 452 \t Time_step: 199 \t Avg_reward: -21.12323 \t Cur_reward: -12.09363\n",
      "Task : 9 \t Episode: 453 \t Time_step: 199 \t Avg_reward: -21.00590 \t Cur_reward: -12.11075\n",
      "Task : 9 \t Episode: 454 \t Time_step: 199 \t Avg_reward: -20.90890 \t Cur_reward: -14.99735\n",
      "Task : 9 \t Episode: 455 \t Time_step: 199 \t Avg_reward: -20.85143 \t Cur_reward: -14.77435\n",
      "Task : 9 \t Episode: 456 \t Time_step: 199 \t Avg_reward: -20.70181 \t Cur_reward: -12.30868\n",
      "Task : 9 \t Episode: 457 \t Time_step: 199 \t Avg_reward: -20.77034 \t Cur_reward: -17.12221\n",
      "Task : 9 \t Episode: 458 \t Time_step: 199 \t Avg_reward: -20.68394 \t Cur_reward: -15.01170\n",
      "Task : 9 \t Episode: 459 \t Time_step: 199 \t Avg_reward: -20.75926 \t Cur_reward: -15.30338\n",
      "Task : 9 \t Episode: 460 \t Time_step: 199 \t Avg_reward: -20.75480 \t Cur_reward: -11.82691\n",
      "Task : 9 \t Episode: 461 \t Time_step: 199 \t Avg_reward: -20.63122 \t Cur_reward: -12.93063\n",
      "Task : 9 \t Episode: 462 \t Time_step: 199 \t Avg_reward: -20.63158 \t Cur_reward: -10.99328\n",
      "Task : 9 \t Episode: 463 \t Time_step: 199 \t Avg_reward: -20.66970 \t Cur_reward: -13.03078\n",
      "Task : 9 \t Episode: 464 \t Time_step: 199 \t Avg_reward: -20.72060 \t Cur_reward: -13.84627\n",
      "done\n",
      "Task : 9 \t Episode: 465 \t Time_step: 101 \t Avg_reward: -20.69702 \t Cur_reward: -6.58172\n",
      "done\n",
      "Task : 9 \t Episode: 466 \t Time_step: 33 \t Avg_reward: -20.54058 \t Cur_reward: -3.54088\n",
      "done\n",
      "Task : 9 \t Episode: 467 \t Time_step: 104 \t Avg_reward: -20.35606 \t Cur_reward: -8.32872\n",
      "Task : 9 \t Episode: 468 \t Time_step: 199 \t Avg_reward: -20.39396 \t Cur_reward: -24.78016\n",
      "done\n",
      "Task : 9 \t Episode: 469 \t Time_step: 50 \t Avg_reward: -20.31520 \t Cur_reward: -3.20856\n",
      "Task : 9 \t Episode: 470 \t Time_step: 199 \t Avg_reward: -20.22936 \t Cur_reward: -12.75040\n",
      "Task : 9 \t Episode: 471 \t Time_step: 199 \t Avg_reward: -20.22307 \t Cur_reward: -15.75788\n",
      "Task : 9 \t Episode: 472 \t Time_step: 199 \t Avg_reward: -20.39446 \t Cur_reward: -26.85924\n",
      "Task : 9 \t Episode: 473 \t Time_step: 199 \t Avg_reward: -20.36663 \t Cur_reward: -16.52210\n",
      "Task : 9 \t Episode: 474 \t Time_step: 199 \t Avg_reward: -20.34982 \t Cur_reward: -18.93028\n",
      "Task : 9 \t Episode: 475 \t Time_step: 199 \t Avg_reward: -20.25431 \t Cur_reward: -18.39215\n",
      "Task : 9 \t Episode: 476 \t Time_step: 199 \t Avg_reward: -20.10151 \t Cur_reward: -17.94309\n",
      "Task : 9 \t Episode: 477 \t Time_step: 199 \t Avg_reward: -20.04380 \t Cur_reward: -17.85950\n",
      "Task : 9 \t Episode: 478 \t Time_step: 199 \t Avg_reward: -20.01278 \t Cur_reward: -15.24548\n",
      "Task : 9 \t Episode: 479 \t Time_step: 199 \t Avg_reward: -19.99571 \t Cur_reward: -21.04237\n",
      "Task : 9 \t Episode: 480 \t Time_step: 199 \t Avg_reward: -20.05666 \t Cur_reward: -14.62725\n",
      "Task : 9 \t Episode: 481 \t Time_step: 199 \t Avg_reward: -20.07574 \t Cur_reward: -16.73690\n",
      "Task : 9 \t Episode: 482 \t Time_step: 199 \t Avg_reward: -20.11512 \t Cur_reward: -21.06062\n",
      "done\n",
      "Task : 9 \t Episode: 483 \t Time_step: 107 \t Avg_reward: -20.00997 \t Cur_reward: -8.09801\n",
      "Task : 9 \t Episode: 484 \t Time_step: 199 \t Avg_reward: -19.98032 \t Cur_reward: -21.78812\n",
      "Task : 9 \t Episode: 485 \t Time_step: 199 \t Avg_reward: -19.97942 \t Cur_reward: -20.83935\n",
      "Task : 9 \t Episode: 486 \t Time_step: 199 \t Avg_reward: -20.00133 \t Cur_reward: -19.36773\n",
      "Task : 9 \t Episode: 487 \t Time_step: 199 \t Avg_reward: -19.98692 \t Cur_reward: -22.90277\n",
      "Task : 9 \t Episode: 488 \t Time_step: 199 \t Avg_reward: -19.99392 \t Cur_reward: -21.52702\n",
      "Task : 9 \t Episode: 489 \t Time_step: 199 \t Avg_reward: -19.93888 \t Cur_reward: -16.85270\n",
      "Task : 9 \t Episode: 490 \t Time_step: 199 \t Avg_reward: -19.94835 \t Cur_reward: -22.24398\n",
      "Task : 9 \t Episode: 491 \t Time_step: 199 \t Avg_reward: -19.86387 \t Cur_reward: -17.47513\n",
      "Task : 9 \t Episode: 492 \t Time_step: 199 \t Avg_reward: -19.73752 \t Cur_reward: -16.62512\n",
      "Task : 9 \t Episode: 493 \t Time_step: 199 \t Avg_reward: -19.63843 \t Cur_reward: -17.27077\n",
      "done\n",
      "Task : 9 \t Episode: 494 \t Time_step: 90 \t Avg_reward: -19.48656 \t Cur_reward: -9.38416\n",
      "Task : 9 \t Episode: 495 \t Time_step: 199 \t Avg_reward: -19.46953 \t Cur_reward: -28.27227\n",
      "done\n",
      "Task : 9 \t Episode: 496 \t Time_step: 97 \t Avg_reward: -19.27260 \t Cur_reward: -8.54412\n",
      "Task : 9 \t Episode: 497 \t Time_step: 199 \t Avg_reward: -19.14826 \t Cur_reward: -14.18421\n",
      "Task : 9 \t Episode: 498 \t Time_step: 199 \t Avg_reward: -19.10099 \t Cur_reward: -21.05763\n",
      "Task : 9 \t Episode: 499 \t Time_step: 199 \t Avg_reward: -18.96406 \t Cur_reward: -14.36130\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(goal_pos) - 49):\n",
    "    j = 9\n",
    "    indices = range(j)+range(j+1,50)\n",
    "    U, S = ttool.tucker_dcmp(all_weights[indices], eps_or_k = rank)\n",
    "    temp = np.tensordot(S, U[1], axes = (1,-1))\n",
    "    L = np.tensordot(temp,U[2], axes = (1,-1))\n",
    "    S = U[0][j-1]\n",
    "    S = np.expand_dims(S, axis = -1)\n",
    "    S = np.expand_dims(S, axis = -1)\n",
    "#     print(S)\n",
    "    # actor = ActorNetwork(sess, state_dim, action_dim, action_bound, hidden_layer_dim = [40,30], \\\n",
    "    #                      seed = RANDOM_SEED, tau = TAU, learning_rate = ACTOR_LEARNING_RATE)\n",
    "    \n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    L_tensor = tf.constant(L, dtype = tf.float32)\n",
    "    S_tensor = tf.constant(S, dtype = tf.float32)\n",
    "#     L_paras = [v for v in tf.trainable_variables() if 'actor' in v.name and 'L' in v.name]\n",
    "#     S_paras = [v for v in tf.trainable_variables() if 'actor' in v.name and 'S' in v.name]\n",
    "    initializeL = [v.assign(L_tensor) for v in tf.trainable_variables() if 'actor' in v.name and 'L' in v.name]\n",
    "    initializeS = [v.assign(S_tensor) for v in tf.trainable_variables() if 'actor' in v.name and 'S' in v.name]\n",
    "    sess.run([initializeL, initializeS])\n",
    "#     temp_L, temp_S = sess.run([L_paras, S_paras])\n",
    "#     print(temp_S)\n",
    "    env.set_goal(np.append(goal_pos[j], [0,0]))\n",
    "    all_sum_reward_list = []\n",
    "    all_avg_reward_list = []\n",
    "    all_reward_list = []\n",
    "    all_loss_list = []\n",
    "    all_t_list = []\n",
    "    \n",
    "    for i in range(MAX_EPISODE):\n",
    "\n",
    "        state = env.reset()\n",
    "        noise.reset()\n",
    "        reward_list = []\n",
    "        loss_list = []\n",
    "\n",
    "        for t in range(MAX_TIME):\n",
    "            action = actor.predict(np.reshape(state, (-1, state_dim))) \n",
    "            action += noise.noise()\n",
    "            action = np.clip(action, -action_bound, action_bound)\n",
    "            action = np.reshape(action, action_dim)\n",
    "\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            replay_buffer.add_sample(np.reshape(state, state_dim), \\\n",
    "                                     np.reshape(action,action_dim),\\\n",
    "                                     reward,\\\n",
    "                                     np.reshape(next_state,state_dim),\\\n",
    "                                     done)\n",
    "\n",
    "            mini_batch = replay_buffer.rand_sample(batch_size = BATCH_SIZE, seed = RANDOM_SEED + t + i*MAX_TIME)\n",
    "            s_batch, a_batch, r_batch, s2_batch, t_batch = mini_batch\n",
    "\n",
    "            a2_batch = actor.predict(s2_batch, if_target = True)\n",
    "            training_q = r_batch + GAMMA * critic.predict(s2_batch, a2_batch, if_target = True) #* ~t_batch\n",
    "\n",
    "            _, loss = critic.train(s_batch, a_batch, training_q)\n",
    "\n",
    "            train_action_batch = actor.predict(s_batch)\n",
    "            critic_grad = critic.compute_critic_gradient(s_batch, train_action_batch)\n",
    "            actor.train(s_batch, critic_grad[0])\n",
    "\n",
    "            actor.update_target_network()\n",
    "            critic.update_target_network()\n",
    "\n",
    "            reward_list.append(reward)\n",
    "            loss_list.append(loss)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    #         print('Episode: %s \\t Action: %s, %s \\t State: %s,%s,%s,%s' %(i, action[0], action[1], state[0],state[1],state[2],state[3]))\n",
    "\n",
    "        all_sum_reward_list.append(np.sum(reward_list))\n",
    "        all_avg_reward_list.append(np.mean(all_sum_reward_list[-100:]))\n",
    "        all_reward_list.append(reward_list)\n",
    "        all_loss_list.append(loss_list)\n",
    "        all_t_list.append(t)\n",
    "\n",
    "        print('Task : %s \\t Episode: %s \\t Time_step: %s \\t Avg_reward: %3.5f \\t Cur_reward: %3.5f'%(j, i, t, all_avg_reward_list[-1], all_sum_reward_list[-1]))\n",
    "#     temp_L, temp_S = sess.run([L_paras, S_paras])\n",
    "#     print(temp_S)\n",
    "    summary_sum_reward_list[j] = np.array(all_sum_reward_list)\n",
    "    summary_avg_reward_list[j] = np.array(all_avg_reward_list)\n",
    "    record_actor_paras = [v for v in tf.trainable_variables() if 'actor_target' in v.name]\n",
    "    record_critic_paras = [v for v in tf.trainable_variables() if 'critic_target' in v.name]\n",
    "    all_recorded_actor_paras.append(sess.run(record_actor_paras))\n",
    "    all_recorded_critic_paras.append(sess.run(record_critic_paras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('./Data/reaching_ddpg_rbf_transfer_500/9.npz', summary_avg_reward_list, summary_sum_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "[print(v.shape) for v in U]\n",
    "print(S.shape)\n",
    "\n",
    "test = np.tensordot(S, U[1], axes = (1,-1))\n",
    "print(test.shape)\n",
    "\n",
    "test2 = np.tensordot(test, U[2], axes = (1,-1))\n",
    "print(test2.shape)\n",
    "\n",
    "test3 = np.array([ np.sum(np.array([ U[0][v][i]*test2[i]  for i in range(10)]), axis = 0) for v in range(50)])\n",
    "# test3 = np.tensordot(test2,U[0], axes = (-1,0))\n",
    "# print(test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(all_avg_reward_list)\n",
    "plt.plot(all_sum_reward_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(np.mean(summary_sum_reward_list, axis = 0))\n",
    "plt.plot(np.mean(summary_avg_reward_list, axis = 0))\n",
    "indexis = np.arange(0,500,10)\n",
    "errors = np.std(summary_avg_reward_list, axis = 0)\n",
    "means = np.mean(summary_avg_reward_list, axis = 0)\n",
    "plt.errorbar(indexis, means[indexis], errors[indexis])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor/L:0\n",
      "actor/S:0\n",
      "actor_target/L:0\n",
      "actor_target/S:0\n",
      "critic/weights_state:0\n",
      "critic/weights_action:0\n",
      "critic/weights_hidden:0\n",
      "critic/bias:0\n",
      "critic_target/weights_state:0\n",
      "critic_target/weights_action:0\n",
      "critic_target/weights_hidden:0\n",
      "critic_target/bias:0\n"
     ]
    }
   ],
   "source": [
    "actor_paras = [v for v in tf.trainable_variables() if 'actor' in v.name]\n",
    "critic_paras = [v for v in tf.trainable_variables() if 'critic' in v.name]\n",
    "print_actor = [print(v.name) for v in tf.trainable_variables() if 'actor' in v.name]\n",
    "print_critic = [print(v.name) for v in tf.trainable_variables() if 'critic' in v.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "actor_p, critic_p = sess.run([actor_paras, critic_paras])\n",
    "actor_init = [v.initialized_value() for v in actor_paras]\n",
    "critic_init = [v.initialized_value() for v in critic_paras]\n",
    "actor_i, critic_i = sess.run([actor_init, critic_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,51,2) into shape (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dd10d5f6cc08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Data/reaching_ddpg_rbf_transfer_50/01.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_recorded_actor_paras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_recorded_critic_paras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_avg_reward_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_sum_reward_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msavez\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \"\"\"\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0m_savez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 format.write_array(fid, np.asanyarray(val),\n\u001b[0m\u001b[1;32m    638\u001b[0m                                    \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                                    pickle_kwargs=pickle_kwargs)\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (10,51,2) into shape (10)"
     ]
    }
   ],
   "source": [
    "np.savez('./Data/reaching_ddpg_rbf_transfer_50/01.npz', all_recorded_actor_paras, all_recorded_critic_paras, summary_avg_reward_list, summary_sum_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savez('./Data/reaching_ddpg_rbf_transfer_50/04.npz', summary_avg_reward_list, summary_sum_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 51, 2)\n"
     ]
    }
   ],
   "source": [
    "print(all_recorded_actor_paras[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
